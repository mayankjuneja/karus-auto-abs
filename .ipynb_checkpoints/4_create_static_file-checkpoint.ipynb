{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 12 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from pandarallel import pandarallel\n",
    "import re\n",
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "\n",
    "pandarallel.initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/kn/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "n = 750\n",
    "pd.set_option('display.max_columns', n)\n",
    "pd.set_option('display.max_rows', n)\n",
    "pd.set_option('display.max_colwidth', -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term = 'AmeriCredit Automobile Receivables Trust 2017-1 Data Tape'\n",
    "finder = re.compile('\\d{4,}\\W\\d{1,}')\n",
    "add_id = re.findall(finder, term)[0]\n",
    "add_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/kn/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (38,39,57) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1578687, 73)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load abs\n",
    "folder = 'data/transaction/'\n",
    "file = '{}.csv'.format(term)\n",
    "path = folder + file\n",
    "data = pd.read_csv(path)\n",
    "init_shape = data.shape[0]\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1578687, 73)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop_duplicates(subset = ['assetNumber', 'reportingPeriodBeginningDate'], keep = 'first')\n",
    "sec_shape = data.shape[0]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching shapes\n"
     ]
    }
   ],
   "source": [
    "if init_shape == sec_shape:\n",
    "    print('Matching shapes')\n",
    "else:\n",
    "    sys.exit('DUPLICATE ROWS')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fields\n",
    "f_folder = 'data/json/fields/'\n",
    "f_file = 'fields.json'\n",
    "f_path = f_folder + f_file\n",
    "with open(f_path) as f:\n",
    "    fields = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mapper\n",
    "m_folder = 'data/dictionary/mapper/'\n",
    "m_file = 'mapper.json'\n",
    "m_path = m_folder + m_file\n",
    "with open(m_path) as f:\n",
    "    mapper = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_id = fields['init_id'][0]\n",
    "date_cols = fields['dates']\n",
    "replacer_cols = fields['replace_dash']\n",
    "clean_cols = fields['clean']\n",
    "m_cols = fields['map']\n",
    "event_cols = fields['event']\n",
    "loc_cols = fields['all_loc']\n",
    "numeric_cols = fields['numeric']\n",
    "all_vals_cols = fields['all_vals']\n",
    "min_max_cols = fields['min_max']\n",
    "west = fields['regions']['west']\n",
    "south_west = fields['regions']['south_west']\n",
    "south_east = fields['regions']['south_east']\n",
    "mid_west = fields['regions']['mid_west']\n",
    "north_east = fields['regions']['north_east']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID and dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_date(init):\n",
    "    \n",
    "    \"\"\"\n",
    "    Reorder date\n",
    "    \"\"\"\n",
    "    \n",
    "    init = str(init)\n",
    "    if init != '-':\n",
    "        if '/' not in init:\n",
    "            y = init[6:10]\n",
    "            m = init[0:2]\n",
    "            d = init[3:5]\n",
    "            date = y + '-' + m + '-' + d\n",
    "        elif '/' in init:\n",
    "            y = init[3:7]\n",
    "            m = init[0:2]\n",
    "            date = y + '-' + m\n",
    "    else:\n",
    "        date = ''\n",
    "    \n",
    "    return date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['id'] = data[init_id].str.replace('=', '').str.replace('\"', '').str.strip() + '-' + add_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reportingPeriodBeginningDate\n",
      "DemandResolutionDate\n",
      "reportingPeriodEndingDate\n",
      "loanMaturityDate\n",
      "originationDate\n",
      "interestPaidThroughDate\n",
      "originalFirstPaymentDate\n",
      "mostRecentServicingTransferReceivedDate\n",
      "zeroBalanceEffectiveDate\n"
     ]
    }
   ],
   "source": [
    "for col in date_cols:\n",
    "    print(col)\n",
    "    values = data[col].values\n",
    "    dates = [reorder_date(v) for v in values]\n",
    "    data['{}R'.format(col)] = dates\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_col = 'loanMaturityDate'\n",
    "# t_col = '{}R'.format(s_col)\n",
    "# data[[s_col, t_col]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[replacer_cols] = data[replacer_cols].replace('-', np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean cols\n",
    "for col in clean_cols:\n",
    "    data[col] = data[col].str.strip()\n",
    "    data[col] = data[col].astype(float)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_val(init, column):\n",
    "    \n",
    "    \"\"\"\n",
    "    Replace numeric values\n",
    "    \"\"\"\n",
    "    \n",
    "    init = str(init).strip().replace(';', '')\n",
    "    if init in ['0', '1', '2', '3', '4', '5', '98', '99']:\n",
    "        mapped = mapper[column][init]\n",
    "        return mapped\n",
    "    else:\n",
    "        if init[0] in ['0', '1', '2', '3', '4', '5']:\n",
    "            use = init[0]\n",
    "        elif init == '-':\n",
    "            use_keys = list(mapper[column].keys())\n",
    "            if '98' in use_keys:\n",
    "                use = '98'\n",
    "            elif '99' in use_keys:\n",
    "                use = '99'\n",
    "        else:\n",
    "            use = init\n",
    "        mapped = mapper[column][use]\n",
    "        \n",
    "    return mapped\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obligorIncomeVerificationLevelCode\n",
      "interestCalculationTypeCode\n",
      "zeroBalanceCode\n",
      "modificationTypeCode\n",
      "assetSubjectDemandStatusCode\n",
      "repurchaseReplacementReasonCode\n",
      "vehicleValueSourceCode\n",
      "obligorEmploymentVerificationCode\n",
      "vehicleNewUsedCode\n",
      "vehicleTypeCode\n",
      "paymentTypeCode\n",
      "servicingAdvanceMethodCode\n",
      "originalInterestRateTypeCode\n",
      "subvented\n"
     ]
    }
   ],
   "source": [
    "for col in m_cols:\n",
    "    print(col)\n",
    "    values = data[col].values\n",
    "    ret_vals = [replace_val(v, col) for v in values]\n",
    "    data['{}M'.format(col)] = ret_vals\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_col = 'subvented'\n",
    "# t_col = '{}M'.format(s_col)\n",
    "# data[[s_col, t_col]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Account status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acct_status(row, b_col, e_col, zero_col, thresh):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create karus account status\n",
    "    \"\"\"\n",
    "    \n",
    "    b = float(row[b_col])\n",
    "    e = float(row[e_col])\n",
    "    z = str(row[zero_col])\n",
    "    \n",
    "    if z in ['Charged-off', 'Repurchased or Replaced']:\n",
    "        res = z\n",
    "        return res\n",
    "    if b < thresh and e < thresh:\n",
    "        res = 'Prepaid or Matured'\n",
    "        return res\n",
    "    if z in ['Unavailable', 'Prepaid or Matured']:\n",
    "        res = z\n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_col = 'reportingPeriodBeginningLoanBalanceAmount'\n",
    "e_col = 'nextReportingPeriodPaymentAmountDue'\n",
    "z_col = 'zeroBalanceCodeM'\n",
    "thresh = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['accountStatus'] = data.parallel_apply(acct_status, args = (b_col, e_col, z_col, thresh, ), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unavailable                1524583\n",
       "Charged-off                27261  \n",
       "Prepaid or Matured         26795  \n",
       "Repurchased or Replaced    48     \n",
       "Name: accountStatus, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['accountStatus'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currentDelinquencyStatus\n",
      "paymentToIncomePercentage\n",
      "paymentExtendedNumber\n",
      "otherAssessedUncollectedServicerFeeAmount\n",
      "totalActualAmountPaid\n",
      "actualInterestCollectedAmount\n",
      "remainingTermToMaturityNumber\n",
      "reportingPeriodScheduledPaymentAmount\n",
      "vehicleValueAmount\n",
      "reportingPeriodInterestRatePercentage\n",
      "scheduledInterestAmount\n",
      "actualPrincipalCollectedAmount\n",
      "actualOtherCollectedAmount\n",
      "reportingPeriodActualEndBalanceAmount\n",
      "servicingFlatFeeAmount\n",
      "chargedoffPrincipalAmount\n",
      "servicingFeePercentage\n",
      "otherPrincipalAdjustmentAmount\n",
      "obligorCreditScore\n",
      "originalInterestRatePercentage\n",
      "nextReportingPeriodPaymentAmountDue\n",
      "gracePeriodNumber\n",
      "originalLoanTerm\n",
      "repurchaseAmount\n",
      "recoveredAmount\n",
      "servicerAdvancedAmount\n",
      "originalLoanAmount\n",
      "repossessedProceedsAmount\n",
      "nextInterestRatePercentage\n",
      "scheduledPrincipalAmount\n",
      "reportingPeriodBeginningLoanBalanceAmount\n"
     ]
    }
   ],
   "source": [
    "# force convert cols to numeric\n",
    "for col in numeric_cols:\n",
    "    print(col)\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = 'id'\n",
    "status_col = 'accountStatus'\n",
    "values = ['Charged-off', 'Prepaid or Matured', 'Repurchased or Replaced']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50671"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = list(data[id_col].unique())\n",
    "#all_ids = all_ids[:1000]\n",
    "print_vals = list(range(0, len(all_ids), 100))\n",
    "len(all_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break ids into list chunks\n",
    "num = 1000\n",
    "id_lists = [all_ids[i:i + num] for i in range(0, len(all_ids), num)]  \n",
    "#id_lists = [id_lists[-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_static(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create static df\n",
    "    \"\"\"\n",
    "    \n",
    "    #df = init.reset_values(drop = True)\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    df = df.sort_values('reportingPeriodBeginningDateR', ascending = False)\n",
    "    df['indexAccount'] = df.index\n",
    "    _id = df[id_col].iloc[0]\n",
    "\n",
    "    # dict\n",
    "    account_dict = {}\n",
    "    account_dict[id_col] = _id\n",
    "    account_dict['records'] = len(df)\n",
    "\n",
    "    # current status of loan\n",
    "    for col in loc_cols:\n",
    "        account_dict['{}LocCurrent'.format(col)] = df[col].iloc[0]\n",
    "    for col in min_max_cols:\n",
    "        account_dict['{}MaxCurrent'.format(col)] = df[col].max()\n",
    "        account_dict['{}MinCurrent'.format(col)] = df[col].min()\n",
    "    for col in all_vals_cols:\n",
    "        vals = list(df[col].unique())\n",
    "        use_vals = ' | '.join(str(val) for val in vals)\n",
    "        account_dict['{}ValsCurrent'.format(col)] = use_vals\n",
    "    for col in numeric_cols:\n",
    "        _sum = df[col].sum()\n",
    "        account_dict['{}SumCurrent'.format(col)] = _sum\n",
    "        vec = list(df[col])\n",
    "        vec = [v for v in vec if str(v) != 'nan']\n",
    "        if len(vec) > 0:\n",
    "            _len = len(vec)\n",
    "            weights = sorted([1 + i for i in list(range(_len))], reverse=True)\n",
    "            wa = np.average(vec, weights=weights)\n",
    "            account_dict['{}WeightedCurrent'.format(col)] = wa\n",
    "        else:\n",
    "            account_dict['{}WeightedCurrent'.format(col)] = 0\n",
    "\n",
    "    # event information\n",
    "    init_vals = list(df[status_col].unique())\n",
    "    inter = list(set(values).intersection(init_vals))\n",
    "    if len(inter) > 0:\n",
    "        account_dict['eventOccurred'] = 1\n",
    "        n = df[status_col].where(df[status_col].isin(values)).last_valid_index()\n",
    "        account_dict['eventIndex'] = n\n",
    "        n_bool = True\n",
    "        single = df.loc[[n]]\n",
    "        for col in event_cols:\n",
    "            account_dict['{}Event'.format(col)] = single[col].iloc[0]\n",
    "\n",
    "        # prior to event\n",
    "        init = n+1\n",
    "        sub = df[init:len(df)]\n",
    "        sub.reset_index(drop = True, inplace = True)\n",
    "        account_dict['priorHistory'] = len(sub)\n",
    "        sub_bool = True\n",
    "        if len(sub) > 0:\n",
    "            for col in loc_cols:\n",
    "                account_dict['{}LocPrior'.format(col)] = sub[col].iloc[0]\n",
    "            for col in min_max_cols:\n",
    "                account_dict['{}MinPrior'.format(col)] = sub[col].min()\n",
    "                account_dict['{}MaxPrior'.format(col)] = sub[col].max()\n",
    "            for col in all_vals_cols:\n",
    "                vals = list(sub[col].unique())\n",
    "                use_vals = ' | '.join(str(val) for val in vals)\n",
    "                account_dict['{}ValsPrior'.format(col)] = use_vals\n",
    "            for col in numeric_cols:\n",
    "                account_dict['{}SumPrior'.format(col)] = sub[col].sum()\n",
    "                vec = list(sub[col])\n",
    "                vec = [v for v in vec if str(v) != 'nan']\n",
    "                if len(vec) > 0:\n",
    "                    _len = len(vec)\n",
    "                    weights = sorted([1 + i for i in list(range(_len))], reverse=True)\n",
    "                    wa = np.average(vec, weights=weights)\n",
    "                    account_dict['{}WeightedPrior'.format(col)] = wa\n",
    "                else:\n",
    "                    account_dict['{}WeightedPrior'.format(col)] = 0\n",
    "\n",
    "            # random\n",
    "            len_sub = len(sub)            \n",
    "            s = random.randint(0, len_sub)\n",
    "            if s == len_sub:\n",
    "                s = s -1\n",
    "            r_sub = sub[s:len_sub].reset_index(drop = True)\n",
    "            account_dict['randomIndex'] = s\n",
    "            for col in loc_cols:\n",
    "                account_dict['{}LocRandom'.format(col)] = r_sub[col].iloc[0]\n",
    "            for col in min_max_cols:\n",
    "                account_dict['{}MinRandom'.format(col)] = r_sub[col].min()\n",
    "                account_dict['{}MaxRandom'.format(col)] = r_sub[col].max()\n",
    "            for col in all_vals_cols:\n",
    "                vals = list(r_sub[col].unique())\n",
    "                use_vals = ' | '.join(str(val) for val in vals)\n",
    "                account_dict['{}ValsRandom'.format(col)] = use_vals\n",
    "            for col in numeric_cols:\n",
    "                account_dict['{}SumRandom'.format(col)] = r_sub[col].sum()\n",
    "                vec = list(r_sub[col])\n",
    "                vec = [v for v in vec if str(v) != 'nan']\n",
    "                if len(vec) > 0:\n",
    "                    _len = len(vec)\n",
    "                    weights = sorted([1 + i for i in list(range(_len))], reverse=True)\n",
    "                    wa = np.average(vec, weights=weights)\n",
    "                    account_dict['{}WeightedRandom'.format(col)] = wa\n",
    "                else:\n",
    "                    account_dict['{}WeightedRandom'.format(col)] = 0\n",
    "\n",
    "        # if event is first row of sub       \n",
    "        else:\n",
    "            for col in loc_cols:\n",
    "                account_dict['{}LocPrior'.format(col)] = df[col].iloc[0]\n",
    "            for col in min_max_cols:\n",
    "                account_dict['{}MinPrior'.format(col)] = df[col].min()\n",
    "                account_dict['{}MaxPrior'.format(col)] = df[col].max()\n",
    "            for col in all_vals_cols:\n",
    "                vals = list(df[col].unique())\n",
    "                use_vals = ' | '.join(str(val) for val in vals)\n",
    "                account_dict['{}ValsPrior'.format(col)] = use_vals\n",
    "            for col in numeric_cols:\n",
    "                account_dict['{}SumPrior'.format(col)] = df[col].sum()\n",
    "                account_dict['{}WeightedPrior'.format(col)] = df[col].iloc[0]\n",
    "\n",
    "    # if no event        \n",
    "    else:\n",
    "        account_dict['eventOccurred'] = 0\n",
    "        account_dict['priorHistory'] = len(df)\n",
    "        sub_bool = False\n",
    "        n_bool = False\n",
    "        for col in event_cols:\n",
    "            account_dict['{}Event'.format(col)] = np.nan\n",
    "        for col in loc_cols:\n",
    "            account_dict['{}LocPrior'.format(col)] = np.nan\n",
    "        for col in min_max_cols:\n",
    "            account_dict['{}MinPrior'.format(col)] = np.nan\n",
    "            account_dict['{}MaxPrior'.format(col)] = np.nan\n",
    "        for col in all_vals_cols:\n",
    "            account_dict['{}ValsPrior'.format(col)] = np.nan\n",
    "        for col in numeric_cols:\n",
    "            account_dict['{}SumPrior'.format(col)] = np.nan\n",
    "            account_dict['{}WeightedPrior'.format(col)] = np.nan\n",
    "\n",
    "        # random set to nan\n",
    "        account_dict['randomIndex'] = np.nan\n",
    "        for col in loc_cols:\n",
    "            account_dict['{}LocRandom'.format(col)] = np.nan\n",
    "        for col in min_max_cols:\n",
    "            account_dict['{}MinRandom'.format(col)] = np.nan\n",
    "            account_dict['{}MaxRandom'.format(col)] = np.nan\n",
    "        for col in all_vals_cols:\n",
    "            account_dict['{}ValsRandom'.format(col)] = np.nan\n",
    "        for col in numeric_cols:\n",
    "            account_dict['{}SumRandom'.format(col)] = np.nan\n",
    "            account_dict['{}WeightedRandom'.format(col)] = np.nan\n",
    "\n",
    "    return account_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.01973515423023031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/kn/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/anaconda3/envs/kn/lib/python3.7/site-packages/ipykernel_launcher.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.062666893005371\n",
      "17.572535037994385\n",
      "-----------------------------\n",
      "2000 0.03947030846046062\n",
      "14.290960788726807\n",
      "32.554728984832764\n",
      "-----------------------------\n",
      "3000 0.05920546269069093\n",
      "15.461709022521973\n",
      "48.65125393867493\n",
      "-----------------------------\n",
      "4000 0.07894061692092123\n",
      "13.914179801940918\n",
      "63.24164891242981\n",
      "-----------------------------\n",
      "5000 0.09867577115115155\n",
      "13.463902950286865\n",
      "77.39237976074219\n",
      "-----------------------------\n",
      "6000 0.11841092538138186\n",
      "14.320125341415405\n",
      "92.39389300346375\n",
      "-----------------------------\n",
      "7000 0.13814607961161215\n",
      "13.621060132980347\n",
      "106.74116396903992\n",
      "-----------------------------\n",
      "8000 0.15788123384184247\n",
      "13.620100021362305\n",
      "120.9934709072113\n",
      "-----------------------------\n",
      "9000 0.17761638807207278\n",
      "13.579086065292358\n",
      "135.28383803367615\n",
      "-----------------------------\n",
      "10000 0.1973515423023031\n",
      "13.566781044006348\n",
      "149.5626299381256\n",
      "-----------------------------\n",
      "11000 0.2170866965325334\n",
      "13.370020866394043\n",
      "163.62207579612732\n",
      "-----------------------------\n",
      "12000 0.2368218507627637\n",
      "13.241830825805664\n",
      "177.4897699356079\n",
      "-----------------------------\n",
      "13000 0.256557004992994\n",
      "13.921814203262329\n",
      "192.10718703269958\n",
      "-----------------------------\n",
      "14000 0.2762921592232243\n",
      "13.786574840545654\n",
      "206.58219385147095\n",
      "-----------------------------\n",
      "15000 0.2960273134534546\n",
      "13.334367990493774\n",
      "220.62115001678467\n",
      "-----------------------------\n",
      "16000 0.31576246768368493\n",
      "13.547000885009766\n",
      "234.8710241317749\n",
      "-----------------------------\n",
      "17000 0.33549762191391524\n",
      "21.707532167434692\n",
      "257.3378281593323\n",
      "-----------------------------\n",
      "18000 0.35523277614414556\n",
      "35.23556995391846\n",
      "293.3732590675354\n",
      "-----------------------------\n",
      "19000 0.37496793037437587\n",
      "35.82451391220093\n",
      "329.9776089191437\n",
      "-----------------------------\n",
      "20000 0.3947030846046062\n",
      "35.04094886779785\n",
      "365.7325060367584\n",
      "-----------------------------\n",
      "21000 0.4144382388348365\n",
      "37.26807999610901\n",
      "403.78112411499023\n",
      "-----------------------------\n",
      "22000 0.4341733930650668\n",
      "34.904860973358154\n",
      "439.3879539966583\n",
      "-----------------------------\n",
      "23000 0.4539085472952971\n",
      "35.42770504951477\n",
      "475.57510805130005\n",
      "-----------------------------\n",
      "24000 0.4736437015255274\n",
      "35.57400298118591\n",
      "511.89237093925476\n",
      "-----------------------------\n",
      "25000 0.49337885575575774\n",
      "34.73501801490784\n",
      "547.3300459384918\n",
      "-----------------------------\n",
      "26000 0.513114009985988\n",
      "35.85897397994995\n",
      "583.911474943161\n",
      "-----------------------------\n",
      "27000 0.5328491642162183\n",
      "35.05663013458252\n",
      "619.5974869728088\n",
      "-----------------------------\n",
      "28000 0.5525843184464486\n",
      "35.234474897384644\n",
      "655.4714999198914\n",
      "-----------------------------\n",
      "29000 0.5723194726766789\n",
      "34.64766573905945\n",
      "690.728052854538\n",
      "-----------------------------\n",
      "30000 0.5920546269069092\n",
      "35.170169830322266\n",
      "726.4960310459137\n",
      "-----------------------------\n",
      "31000 0.6117897811371396\n",
      "34.65446496009827\n",
      "761.7577929496765\n",
      "-----------------------------\n",
      "32000 0.6315249353673699\n",
      "34.868412017822266\n",
      "797.2110199928284\n",
      "-----------------------------\n",
      "33000 0.6512600895976002\n",
      "34.5144989490509\n",
      "832.3013050556183\n",
      "-----------------------------\n",
      "34000 0.6709952438278305\n",
      "36.01769685745239\n",
      "868.8759648799896\n",
      "-----------------------------\n",
      "35000 0.6907303980580608\n",
      "35.51242804527283\n",
      "905.078978061676\n",
      "-----------------------------\n",
      "36000 0.7104655522882911\n",
      "34.40355467796326\n",
      "940.0317418575287\n",
      "-----------------------------\n",
      "37000 0.7302007065185214\n",
      "34.77989912033081\n",
      "975.4166829586029\n",
      "-----------------------------\n",
      "38000 0.7499358607487517\n",
      "34.503499031066895\n",
      "1010.4639940261841\n",
      "-----------------------------\n",
      "39000 0.769671014978982\n",
      "34.91905498504639\n",
      "1045.97487783432\n",
      "-----------------------------\n",
      "40000 0.7894061692092124\n",
      "34.85419797897339\n",
      "1081.361585855484\n",
      "-----------------------------\n",
      "41000 0.8091413234394427\n",
      "35.12855410575867\n",
      "1117.0810108184814\n",
      "-----------------------------\n",
      "42000 0.828876477669673\n",
      "34.145833015441895\n",
      "1151.7241439819336\n",
      "-----------------------------\n",
      "43000 0.8486116318999033\n",
      "35.04437804222107\n",
      "1187.2584660053253\n",
      "-----------------------------\n",
      "44000 0.8683467861301336\n",
      "34.78160834312439\n",
      "1222.5666711330414\n",
      "-----------------------------\n",
      "45000 0.8880819403603639\n",
      "34.92287588119507\n",
      "1257.9785029888153\n",
      "-----------------------------\n",
      "46000 0.9078170945905942\n",
      "33.973644733428955\n",
      "1292.4157829284668\n",
      "-----------------------------\n",
      "47000 0.9275522488208245\n",
      "34.9422390460968\n",
      "1327.82484292984\n",
      "-----------------------------\n",
      "48000 0.9472874030510549\n",
      "34.06211495399475\n",
      "1362.3608949184418\n",
      "-----------------------------\n",
      "49000 0.9670225572812852\n",
      "34.51526188850403\n",
      "1397.3377029895782\n",
      "-----------------------------\n",
      "50000 0.9867577115115155\n",
      "33.98791289329529\n",
      "1431.801831960678\n",
      "-----------------------------\n",
      "50671 1.0\n",
      "22.71270513534546\n",
      "1454.8464031219482\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "log = {}\n",
    "log['securitization'] = term\n",
    "master_list = []\n",
    "broke = 0\n",
    "cautions = 0\n",
    "status = 'good'\n",
    "s1 = time.time()\n",
    "ids_count = 0\n",
    "for ids in id_lists:\n",
    "    \n",
    "    # get update\n",
    "    ids_count = ids_count + len(ids)\n",
    "    percent = ids_count / len(all_ids)\n",
    "    print(ids_count, percent)\n",
    "    \n",
    "    # create sub\n",
    "    sub_df = data[data[id_col].isin(ids)]\n",
    "    sub_df['indexTransaction'] = sub_df.index\n",
    "    sub_df = sub_df.reset_index(drop = True)\n",
    "    splits = list(sub_df.groupby(id_col)) \n",
    "    l = [splits[n_][1] for n_ in list(range(len(splits)))]\n",
    "    a = np.array(l)\n",
    "    \n",
    "    # get results\n",
    "    s2 = time.time()\n",
    "    try:\n",
    "        results = [convert_static(d) for d in a]\n",
    "        for r in results:\n",
    "            master_list.append(r)\n",
    "    except:\n",
    "        try:\n",
    "            cautions = cautions + 1\n",
    "            print('HITTING EXCEPTION')\n",
    "            for l2 in l:\n",
    "                res = convert_static(l2)\n",
    "                master_list.append(res)\n",
    "        except:\n",
    "            status = 'bad'\n",
    "            broke = broke + 1\n",
    "            if broke > 0:\n",
    "                sys.exit('Too many errors...')\n",
    "    \n",
    "    e1 = time.time()\n",
    "    e2 = time.time()\n",
    "    log['{}'.format(ids_count)] = (e2 - s2)\n",
    "    \n",
    "    print(e2 - s2)\n",
    "    print(e1 - s1)\n",
    "    print('-----------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "log['total_time'] = e1 - s1\n",
    "log['run_status'] = status\n",
    "log['cautions'] = cautions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.DataFrame(master_list)\n",
    "log['loans'] = len(master)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = master['obligorCreditScoreLocCurrent'].mean()\n",
    "if cs <= 600:\n",
    "    rating = 'sub_prime'\n",
    "elif cs > 600 and cs <= 700:\n",
    "    rating = 'near_prime'\n",
    "elif cs > 720:\n",
    "    rating = 'prime'\n",
    "else:\n",
    "    rating = 'other'\n",
    "log['average_credit'] = cs\n",
    "log['rating'] = rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_ids) == len(master_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prepaid or Matured         25244\n",
       "NaN                        15586\n",
       "Charged-off                9795 \n",
       "Repurchased or Replaced    46   \n",
       "Name: accountStatusEvent, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master['accountStatusEvent'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding final fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['securitization'] = term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(row):\n",
    "    \n",
    "    \"\"\"\n",
    "    Set target var\n",
    "    \"\"\"\n",
    "    \n",
    "    init = str(row['accountStatusEvent'])\n",
    "    remaining = row['remainingTermToMaturityNumberMinPrior']\n",
    "    #remaining = row['remainingTermToMaturityNumberLocCurrent']\n",
    "    #remaining = row['remainingTermToMaturityNumberLocPrior']\n",
    "    \n",
    "    if init == 'Charged-off':\n",
    "        res = 'Charged-off'\n",
    "        return res\n",
    "    elif init == 'Prepaid or Matured' and remaining > 1:\n",
    "        res = 'Prepaid'\n",
    "        return res\n",
    "    elif init == 'Prepaid or Matured' and remaining < 2:\n",
    "        res = 'Closed'\n",
    "        return res\n",
    "    elif init == 'nan':\n",
    "        res = 'Active or other'\n",
    "        return res\n",
    "    else:\n",
    "        res = 'Active or other'\n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['target'] = master.apply(get_target, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prepaid            21185\n",
       "Active or other    15632\n",
       "Charged-off        9795 \n",
       "Closed             4059 \n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master['target'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_regions(state):\n",
    "    \n",
    "    \"\"\"\n",
    "    Get region\n",
    "    \"\"\"\n",
    "    \n",
    "    if state in west:\n",
    "        return 'West'\n",
    "    elif state in south_west:\n",
    "        return 'SouthWest'\n",
    "    elif state in south_east:\n",
    "        return 'SouthEast'\n",
    "    elif state in mid_west:\n",
    "        return 'MidWest'\n",
    "    elif state in north_east:\n",
    "        return 'NorthEast'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['region'] = np.nan\n",
    "    \n",
    "master['region'] = master['obligorGeographicLocationLocCurrent'].apply(finding_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_year(init):\n",
    "    \n",
    "    \"\"\"\n",
    "    Get origination year\n",
    "    \"\"\"\n",
    "    \n",
    "    year = init[0:4]\n",
    "    \n",
    "    return year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_col = 'originationDateRLocCurrent'\n",
    "\n",
    "year_vals = master[year_col].values\n",
    "years = [get_or_year(y) for y in year_vals]\n",
    "master['originationYear'] = years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50671, 711)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding outcome for transaction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_col = 'id'\n",
    "m_type = 'left'\n",
    "merged = pd.merge(data, master[[m_col, 'target']], on = m_col, how = m_type)\n",
    "ft_shape = merged.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1578687"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_shape == sec_shape == ft_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vals cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_cols = [col for col in list(master.columns) if 'vals' in col.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_vals(row, column):\n",
    "\n",
    "    \"\"\"\n",
    "    Fix column values\n",
    "    \"\"\"\n",
    "\n",
    "    init = str(row[column])\n",
    "\n",
    "    ret_val = 'str: ' + init\n",
    "\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obligorIncomeVerificationLevelCodeValsCurrent\n",
      "interestCalculationTypeCodeValsCurrent\n",
      "zeroBalanceCodeValsCurrent\n",
      "subventedValsCurrent\n",
      "modificationTypeCodeValsCurrent\n",
      "assetSubjectDemandStatusCodeValsCurrent\n",
      "repurchaseReplacementReasonCodeValsCurrent\n",
      "vehicleValueSourceCodeValsCurrent\n",
      "accountStatusValsCurrent\n",
      "obligorEmploymentVerificationCodeValsCurrent\n",
      "originalInterestRateTypeCodeValsCurrent\n",
      "vehicleNewUsedCodeValsCurrent\n",
      "vehicleTypeCodeValsCurrent\n",
      "paymentTypeCodeValsCurrent\n",
      "indexAccountValsCurrent\n",
      "servicingAdvanceMethodCodeValsCurrent\n",
      "indexTransactionValsCurrent\n",
      "zeroBalanceCodeMValsCurrent\n",
      "obligorIncomeVerificationLevelCodeValsPrior\n",
      "interestCalculationTypeCodeValsPrior\n",
      "zeroBalanceCodeValsPrior\n",
      "subventedValsPrior\n",
      "modificationTypeCodeValsPrior\n",
      "assetSubjectDemandStatusCodeValsPrior\n",
      "repurchaseReplacementReasonCodeValsPrior\n",
      "vehicleValueSourceCodeValsPrior\n",
      "accountStatusValsPrior\n",
      "obligorEmploymentVerificationCodeValsPrior\n",
      "originalInterestRateTypeCodeValsPrior\n",
      "vehicleNewUsedCodeValsPrior\n",
      "vehicleTypeCodeValsPrior\n",
      "paymentTypeCodeValsPrior\n",
      "indexAccountValsPrior\n",
      "servicingAdvanceMethodCodeValsPrior\n",
      "indexTransactionValsPrior\n",
      "zeroBalanceCodeMValsPrior\n",
      "obligorIncomeVerificationLevelCodeValsRandom\n",
      "interestCalculationTypeCodeValsRandom\n",
      "zeroBalanceCodeValsRandom\n",
      "subventedValsRandom\n",
      "modificationTypeCodeValsRandom\n",
      "assetSubjectDemandStatusCodeValsRandom\n",
      "repurchaseReplacementReasonCodeValsRandom\n",
      "vehicleValueSourceCodeValsRandom\n",
      "accountStatusValsRandom\n",
      "obligorEmploymentVerificationCodeValsRandom\n",
      "originalInterestRateTypeCodeValsRandom\n",
      "vehicleNewUsedCodeValsRandom\n",
      "vehicleTypeCodeValsRandom\n",
      "paymentTypeCodeValsRandom\n",
      "indexAccountValsRandom\n",
      "servicingAdvanceMethodCodeValsRandom\n",
      "indexTransactionValsRandom\n",
      "zeroBalanceCodeMValsRandom\n"
     ]
    }
   ],
   "source": [
    "for col in vals_cols:\n",
    "    print(col)\n",
    "    master[col] = master[col].astype(str)\n",
    "    master[col] = 'str: ' + master[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/static/AmeriCredit Automobile Receivables Trust 2017-1 Data Tape static.csv\n",
      "(50671, 711)\n"
     ]
    }
   ],
   "source": [
    "e_folder = 'data/static/'\n",
    "e_file = '{} static.csv'.format(term)\n",
    "e_path = e_folder + e_file\n",
    "print(e_path)\n",
    "print(master.shape)\n",
    "master.to_csv(e_path, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/transaction/prepared/AmeriCredit Automobile Receivables Trust 2017-1 Data Tape transaction.csv\n",
      "(1578687, 99)\n"
     ]
    }
   ],
   "source": [
    "t_folder = 'data/transaction/prepared/'\n",
    "t_file = '{} transaction.csv'.format(term)\n",
    "t_path = t_folder + t_file\n",
    "print(t_path)\n",
    "print(merged.shape)\n",
    "merged.to_csv(t_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export log\n",
    "j_folder = 'data/static/log/'\n",
    "j_file = '{} log.json'.format(term)\n",
    "j_path = j_folder + j_file\n",
    "with open(j_path, 'w') as outfile:  \n",
    "    json.dump(log, outfile, indent = 4, separators = (',', ': '), sort_keys = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue...\n"
     ]
    }
   ],
   "source": [
    "print('continue...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
