{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 12 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from pandarallel import pandarallel\n",
    "import re\n",
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "import os\n",
    "from project_functions import get_originator\n",
    "\n",
    "pandarallel.initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/kn/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "n = 750\n",
    "pd.set_option('display.max_columns', n)\n",
    "pd.set_option('display.max_rows', n)\n",
    "pd.set_option('display.max_colwidth', -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = 'Toyota Auto Receivables 2020-D Owner Trust Data Tape'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toyota\n",
      "2020-D\n"
     ]
    }
   ],
   "source": [
    "originator = get_originator(term)[0]\n",
    "finder = re.compile(r'\\b\\d{4}-[A-Za-z\\d]+\\b')\n",
    "init_id = re.search(finder, term)\n",
    "add_id = init_id.group()\n",
    "print(originator)\n",
    "print(add_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/kn/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (33,37,39,40,43,46,48,49,50,51,52,57) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(488632, 73)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load abs\n",
    "folder = 'data/karus_datasets/{}/{} {}/'.format(originator, originator, add_id)\n",
    "file = 'transaction_raw.csv'.format(term)\n",
    "path = folder + file\n",
    "data = pd.read_csv(path)\n",
    "init_shape = data.shape[0]\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fields\n",
    "f_folder = 'data/json/fields/'\n",
    "f_file = 'fields.json'\n",
    "f_path = f_folder + f_file\n",
    "with open(f_path) as f:\n",
    "    fields = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mapper\n",
    "m_folder = 'data/dictionary/mapper/'\n",
    "m_file = 'mapper.json'\n",
    "m_path = m_folder + m_file\n",
    "with open(m_path) as f:\n",
    "    mapper = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_id = fields['init_id'][0]\n",
    "date_cols = fields['dates']\n",
    "replacer_cols = fields['replace_dash']\n",
    "clean_cols = fields['clean']\n",
    "m_cols = fields['map']\n",
    "event_cols = fields['event']\n",
    "loc_cols = fields['all_loc']\n",
    "numeric_cols = fields['numeric']\n",
    "all_vals_cols = fields['all_vals']\n",
    "min_max_cols = fields['min_max']\n",
    "west = fields['regions']['west']\n",
    "south_west = fields['regions']['south_west']\n",
    "south_east = fields['regions']['south_east']\n",
    "mid_west = fields['regions']['mid_west']\n",
    "north_east = fields['regions']['north_east']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID and dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_date(init):\n",
    "    \n",
    "    \"\"\"\n",
    "    Reorder date\n",
    "    \"\"\"\n",
    "    \n",
    "    init = str(init)\n",
    "    if init != '-':\n",
    "        if '/' not in init:\n",
    "            y = init[6:10]\n",
    "            m = init[0:2]\n",
    "            d = init[3:5]\n",
    "            date = y + '-' + m + '-' + d\n",
    "        elif '/' in init:\n",
    "            y = init[3:7]\n",
    "            m = init[0:2]\n",
    "            date = y + '-' + m\n",
    "    else:\n",
    "        date = ''\n",
    "    \n",
    "    return date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['id'] = data[init_id].str.replace('=', '').str.replace('\"', '').str.strip() + '-' + add_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reportingPeriodBeginningDate\n",
      "DemandResolutionDate\n",
      "reportingPeriodEndingDate\n",
      "loanMaturityDate\n",
      "originationDate\n",
      "interestPaidThroughDate\n",
      "originalFirstPaymentDate\n",
      "mostRecentServicingTransferReceivedDate\n",
      "zeroBalanceEffectiveDate\n"
     ]
    }
   ],
   "source": [
    "for col in date_cols:\n",
    "    print(col)\n",
    "    values = data[col].values\n",
    "    dates = [reorder_date(v) for v in values]\n",
    "    data['{}R'.format(col)] = dates\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(422950, 83)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sort_values(by=['reportingPeriodBeginningDateR'], ascending=False)\n",
    "data = data.drop_duplicates(subset = ['id', 'reportingPeriodBeginningDateR'], keep = 'first')\n",
    "sec_shape = data.shape[0]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows\n"
     ]
    }
   ],
   "source": [
    "if init_shape == sec_shape:\n",
    "    dup_rows = False\n",
    "    print('Matching shapes')\n",
    "else:\n",
    "    dup_rows = True \n",
    "    print('Duplicate rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_col = 'loanMaturityDate'\n",
    "# t_col = '{}R'.format(s_col)\n",
    "# data[[s_col, t_col]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[replacer_cols] = data[replacer_cols].replace('-', np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean cols\n",
    "for col in clean_cols:\n",
    "    data[col] = data[col].astype(str)\n",
    "    data[col] = data[col].str.strip()\n",
    "    data[col] = data[col].astype(float)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_val(init, column):\n",
    "    \n",
    "    \"\"\"\n",
    "    Replace numeric values\n",
    "    \"\"\"\n",
    "    \n",
    "    init = str(init).strip().replace(';', '')\n",
    "    if init in ['0', '1', '2', '3', '4', '5', '98', '99']:\n",
    "        mapped = mapper[column][init]\n",
    "        return mapped\n",
    "    else:\n",
    "        if init[0] in ['0', '1', '2', '3', '4', '5']:\n",
    "            use = init[0]\n",
    "        elif init == '-':\n",
    "            use_keys = list(mapper[column].keys())\n",
    "            if '98' in use_keys:\n",
    "                use = '98'\n",
    "            elif '99' in use_keys:\n",
    "                use = '99'\n",
    "        else:\n",
    "            use = init\n",
    "        mapped = mapper[column][use]\n",
    "        \n",
    "    return mapped\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obligorIncomeVerificationLevelCode\n",
      "interestCalculationTypeCode\n",
      "zeroBalanceCode\n",
      "modificationTypeCode\n",
      "assetSubjectDemandStatusCode\n",
      "repurchaseReplacementReasonCode\n",
      "vehicleValueSourceCode\n",
      "obligorEmploymentVerificationCode\n",
      "vehicleNewUsedCode\n",
      "vehicleTypeCode\n",
      "paymentTypeCode\n",
      "servicingAdvanceMethodCode\n",
      "originalInterestRateTypeCode\n",
      "subvented\n"
     ]
    }
   ],
   "source": [
    "for col in m_cols:\n",
    "    print(col)\n",
    "    values = data[col].values\n",
    "    ret_vals = [replace_val(v, col) for v in values]\n",
    "    data['{}M'.format(col)] = ret_vals\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_col = 'subvented'\n",
    "# t_col = '{}M'.format(s_col)\n",
    "# data[[s_col, t_col]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Account status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acct_status(row, b_col, e_col, zero_col, thresh):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create karus account status\n",
    "    \"\"\"\n",
    "    \n",
    "    b = float(row[b_col])\n",
    "    e = float(row[e_col])\n",
    "    z = str(row[zero_col])\n",
    "    \n",
    "    if z in ['Charged-off', 'Repurchased or Replaced']:\n",
    "        res = z\n",
    "        return res\n",
    "    if b < thresh and e < thresh:\n",
    "        res = 'Prepaid or Matured'\n",
    "        return res\n",
    "    if z in ['Unavailable', 'Prepaid or Matured']:\n",
    "        res = z\n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_col = 'reportingPeriodBeginningLoanBalanceAmount'\n",
    "e_col = 'nextReportingPeriodPaymentAmountDue'\n",
    "z_col = 'zeroBalanceCodeM'\n",
    "thresh = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['accountStatus'] = data.parallel_apply(acct_status, args = (b_col, e_col, z_col, thresh, ), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unavailable                414329\n",
       "Prepaid or Matured         8558  \n",
       "Charged-off                62    \n",
       "Repurchased or Replaced    1     \n",
       "Name: accountStatus, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['accountStatus'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currentDelinquencyStatus\n",
      "paymentToIncomePercentage\n",
      "paymentExtendedNumber\n",
      "otherAssessedUncollectedServicerFeeAmount\n",
      "totalActualAmountPaid\n",
      "actualInterestCollectedAmount\n",
      "remainingTermToMaturityNumber\n",
      "reportingPeriodScheduledPaymentAmount\n",
      "vehicleValueAmount\n",
      "reportingPeriodInterestRatePercentage\n",
      "scheduledInterestAmount\n",
      "actualPrincipalCollectedAmount\n",
      "actualOtherCollectedAmount\n",
      "reportingPeriodActualEndBalanceAmount\n",
      "servicingFlatFeeAmount\n",
      "chargedoffPrincipalAmount\n",
      "servicingFeePercentage\n",
      "otherPrincipalAdjustmentAmount\n",
      "obligorCreditScore\n",
      "originalInterestRatePercentage\n",
      "nextReportingPeriodPaymentAmountDue\n",
      "gracePeriodNumber\n",
      "originalLoanTerm\n",
      "repurchaseAmount\n",
      "recoveredAmount\n",
      "servicerAdvancedAmount\n",
      "originalLoanAmount\n",
      "repossessedProceedsAmount\n",
      "nextInterestRatePercentage\n",
      "scheduledPrincipalAmount\n",
      "reportingPeriodBeginningLoanBalanceAmount\n"
     ]
    }
   ],
   "source": [
    "# force convert cols to numeric\n",
    "for col in numeric_cols:\n",
    "    print(col)\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = 'id'\n",
    "status_col = 'accountStatus'\n",
    "values = ['Charged-off', 'Prepaid or Matured', 'Repurchased or Replaced']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87460"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = list(data[id_col].unique())\n",
    "#all_ids = all_ids[:1000]\n",
    "print_vals = list(range(0, len(all_ids), 100))\n",
    "len(all_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break ids into list chunks\n",
    "num = 1000\n",
    "id_lists = [all_ids[i:i + num] for i in range(0, len(all_ids), num)]  \n",
    "#id_lists = [id_lists[-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_static(df, exception_status):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create static df\n",
    "    \"\"\"\n",
    "    \n",
    "    #df = init.reset_values(drop = True)\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    df = df.sort_values('reportingPeriodBeginningDateR', ascending = False)\n",
    "    df['indexAccount'] = df.index\n",
    "    _id = df[id_col].iloc[0]\n",
    "\n",
    "    # dict\n",
    "    account_dict = {}\n",
    "    account_dict['exceptionStatus'] = exception_status\n",
    "    account_dict[id_col] = _id\n",
    "    account_dict['records'] = len(df)\n",
    "\n",
    "    # current status of loan\n",
    "    for col in loc_cols:\n",
    "        account_dict['{}LocCurrent'.format(col)] = df[col].iloc[0]\n",
    "    for col in min_max_cols:\n",
    "        account_dict['{}MaxCurrent'.format(col)] = df[col].max()\n",
    "        account_dict['{}MinCurrent'.format(col)] = df[col].min()\n",
    "    for col in all_vals_cols:\n",
    "        vals = list(df[col].unique())\n",
    "        use_vals = ' | '.join(str(val) for val in vals)\n",
    "        account_dict['{}ValsCurrent'.format(col)] = use_vals\n",
    "    for col in numeric_cols:\n",
    "        _sum = df[col].sum()\n",
    "        account_dict['{}SumCurrent'.format(col)] = _sum\n",
    "        vec = list(df[col])\n",
    "        vec = [v for v in vec if str(v) != 'nan']\n",
    "        if len(vec) > 0:\n",
    "            _len = len(vec)\n",
    "            weights = sorted([1 + i for i in list(range(_len))], reverse=True)\n",
    "            wa = np.average(vec, weights=weights)\n",
    "            account_dict['{}WeightedCurrent'.format(col)] = wa\n",
    "        else:\n",
    "            account_dict['{}WeightedCurrent'.format(col)] = 0\n",
    "\n",
    "    # event information\n",
    "    init_vals = list(df[status_col].unique())\n",
    "    inter = list(set(values).intersection(init_vals))\n",
    "    if len(inter) > 0:\n",
    "        account_dict['eventOccurred'] = 1\n",
    "        n = df[status_col].where(df[status_col].isin(values)).last_valid_index()\n",
    "        account_dict['eventIndex'] = n\n",
    "        n_bool = True\n",
    "        single = df.loc[[n]]\n",
    "        for col in event_cols:\n",
    "            account_dict['{}Event'.format(col)] = single[col].iloc[0]\n",
    "\n",
    "        # prior to event\n",
    "        init = n+1\n",
    "        sub = df[init:len(df)]\n",
    "        sub.reset_index(drop = True, inplace = True)\n",
    "        account_dict['priorHistory'] = len(sub)\n",
    "        sub_bool = True\n",
    "        if len(sub) > 0:\n",
    "            for col in loc_cols:\n",
    "                account_dict['{}LocPrior'.format(col)] = sub[col].iloc[0]\n",
    "            for col in min_max_cols:\n",
    "                account_dict['{}MinPrior'.format(col)] = sub[col].min()\n",
    "                account_dict['{}MaxPrior'.format(col)] = sub[col].max()\n",
    "            for col in all_vals_cols:\n",
    "                vals = list(sub[col].unique())\n",
    "                use_vals = ' | '.join(str(val) for val in vals)\n",
    "                account_dict['{}ValsPrior'.format(col)] = use_vals\n",
    "            for col in numeric_cols:\n",
    "                account_dict['{}SumPrior'.format(col)] = sub[col].sum()\n",
    "                vec = list(sub[col])\n",
    "                vec = [v for v in vec if str(v) != 'nan']\n",
    "                if len(vec) > 0:\n",
    "                    _len = len(vec)\n",
    "                    weights = sorted([1 + i for i in list(range(_len))], reverse=True)\n",
    "                    wa = np.average(vec, weights=weights)\n",
    "                    account_dict['{}WeightedPrior'.format(col)] = wa\n",
    "                else:\n",
    "                    account_dict['{}WeightedPrior'.format(col)] = 0\n",
    "\n",
    "            # random\n",
    "            len_sub = len(sub)            \n",
    "            s = random.randint(0, len_sub)\n",
    "            if s == len_sub:\n",
    "                s = s -1\n",
    "            r_sub = sub[s:len_sub].reset_index(drop = True)\n",
    "            account_dict['randomIndex'] = s\n",
    "            for col in loc_cols:\n",
    "                account_dict['{}LocRandom'.format(col)] = r_sub[col].iloc[0]\n",
    "            for col in min_max_cols:\n",
    "                account_dict['{}MinRandom'.format(col)] = r_sub[col].min()\n",
    "                account_dict['{}MaxRandom'.format(col)] = r_sub[col].max()\n",
    "            for col in all_vals_cols:\n",
    "                vals = list(r_sub[col].unique())\n",
    "                use_vals = ' | '.join(str(val) for val in vals)\n",
    "                account_dict['{}ValsRandom'.format(col)] = use_vals\n",
    "            for col in numeric_cols:\n",
    "                account_dict['{}SumRandom'.format(col)] = r_sub[col].sum()\n",
    "                vec = list(r_sub[col])\n",
    "                vec = [v for v in vec if str(v) != 'nan']\n",
    "                if len(vec) > 0:\n",
    "                    _len = len(vec)\n",
    "                    weights = sorted([1 + i for i in list(range(_len))], reverse=True)\n",
    "                    wa = np.average(vec, weights=weights)\n",
    "                    account_dict['{}WeightedRandom'.format(col)] = wa\n",
    "                else:\n",
    "                    account_dict['{}WeightedRandom'.format(col)] = 0\n",
    "\n",
    "        # if event is first row of sub       \n",
    "        else:\n",
    "            for col in loc_cols:\n",
    "                account_dict['{}LocPrior'.format(col)] = df[col].iloc[0]\n",
    "            for col in min_max_cols:\n",
    "                account_dict['{}MinPrior'.format(col)] = df[col].min()\n",
    "                account_dict['{}MaxPrior'.format(col)] = df[col].max()\n",
    "            for col in all_vals_cols:\n",
    "                vals = list(df[col].unique())\n",
    "                use_vals = ' | '.join(str(val) for val in vals)\n",
    "                account_dict['{}ValsPrior'.format(col)] = use_vals\n",
    "            for col in numeric_cols:\n",
    "                account_dict['{}SumPrior'.format(col)] = df[col].sum()\n",
    "                account_dict['{}WeightedPrior'.format(col)] = df[col].iloc[0]\n",
    "\n",
    "    # if no event        \n",
    "    else:\n",
    "        account_dict['eventOccurred'] = 0\n",
    "        account_dict['priorHistory'] = len(df)\n",
    "        sub_bool = False\n",
    "        n_bool = False\n",
    "        for col in event_cols:\n",
    "            account_dict['{}Event'.format(col)] = np.nan\n",
    "        for col in loc_cols:\n",
    "            account_dict['{}LocPrior'.format(col)] = np.nan\n",
    "        for col in min_max_cols:\n",
    "            account_dict['{}MinPrior'.format(col)] = np.nan\n",
    "            account_dict['{}MaxPrior'.format(col)] = np.nan\n",
    "        for col in all_vals_cols:\n",
    "            account_dict['{}ValsPrior'.format(col)] = np.nan\n",
    "        for col in numeric_cols:\n",
    "            account_dict['{}SumPrior'.format(col)] = np.nan\n",
    "            account_dict['{}WeightedPrior'.format(col)] = np.nan\n",
    "\n",
    "        # random set to nan\n",
    "        account_dict['randomIndex'] = np.nan\n",
    "        for col in loc_cols:\n",
    "            account_dict['{}LocRandom'.format(col)] = np.nan\n",
    "        for col in min_max_cols:\n",
    "            account_dict['{}MinRandom'.format(col)] = np.nan\n",
    "            account_dict['{}MaxRandom'.format(col)] = np.nan\n",
    "        for col in all_vals_cols:\n",
    "            account_dict['{}ValsRandom'.format(col)] = np.nan\n",
    "        for col in numeric_cols:\n",
    "            account_dict['{}SumRandom'.format(col)] = np.nan\n",
    "            account_dict['{}WeightedRandom'.format(col)] = np.nan\n",
    "\n",
    "    return account_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.01143379830779785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/kn/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITTING EXCEPTION\n",
      "14.489802837371826\n",
      "15.631582975387573\n",
      "-----------------------------\n",
      "2000 0.0228675966155957\n",
      "HITTING EXCEPTION\n",
      "14.487663984298706\n",
      "30.55995512008667\n",
      "-----------------------------\n",
      "3000 0.03430139492339355\n",
      "HITTING EXCEPTION\n",
      "15.153934955596924\n",
      "46.23750710487366\n",
      "-----------------------------\n",
      "4000 0.0457351932311914\n",
      "HITTING EXCEPTION\n",
      "14.733017206192017\n",
      "61.55012106895447\n",
      "-----------------------------\n",
      "5000 0.05716899153898925\n",
      "HITTING EXCEPTION\n",
      "14.657129049301147\n",
      "76.75554323196411\n",
      "-----------------------------\n",
      "6000 0.0686027898467871\n",
      "HITTING EXCEPTION\n",
      "14.398237943649292\n",
      "91.61693215370178\n",
      "-----------------------------\n",
      "7000 0.08003658815458495\n",
      "HITTING EXCEPTION\n",
      "15.713167190551758\n",
      "107.78707003593445\n",
      "-----------------------------\n",
      "8000 0.0914703864623828\n",
      "HITTING EXCEPTION\n",
      "14.687680006027222\n",
      "123.08229994773865\n",
      "-----------------------------\n",
      "9000 0.10290418477018065\n",
      "HITTING EXCEPTION\n",
      "14.378167152404785\n",
      "137.9232861995697\n",
      "-----------------------------\n",
      "10000 0.1143379830779785\n",
      "HITTING EXCEPTION\n",
      "14.74588918685913\n",
      "153.22431707382202\n",
      "-----------------------------\n",
      "11000 0.12577178138577635\n",
      "HITTING EXCEPTION\n",
      "16.3407621383667\n",
      "170.10979509353638\n",
      "-----------------------------\n",
      "12000 0.1372055796935742\n",
      "HITTING EXCEPTION\n",
      "14.369132041931152\n",
      "185.00455617904663\n",
      "-----------------------------\n",
      "13000 0.14863937800137206\n",
      "HITTING EXCEPTION\n",
      "13.932068109512329\n",
      "199.4347379207611\n",
      "-----------------------------\n",
      "14000 0.1600731763091699\n",
      "HITTING EXCEPTION\n",
      "14.613118886947632\n",
      "214.54381489753723\n",
      "-----------------------------\n",
      "15000 0.17150697461696776\n",
      "HITTING EXCEPTION\n",
      "14.664849996566772\n",
      "229.7658131122589\n",
      "-----------------------------\n",
      "16000 0.1829407729247656\n",
      "HITTING EXCEPTION\n",
      "15.453084945678711\n",
      "245.81655097007751\n",
      "-----------------------------\n",
      "17000 0.19437457123256346\n",
      "HITTING EXCEPTION\n",
      "14.411922931671143\n",
      "260.71584391593933\n",
      "-----------------------------\n",
      "18000 0.2058083695403613\n",
      "HITTING EXCEPTION\n",
      "14.991844892501831\n",
      "276.1920599937439\n",
      "-----------------------------\n",
      "19000 0.21724216784815917\n",
      "HITTING EXCEPTION\n",
      "14.914003133773804\n",
      "291.6314730644226\n",
      "-----------------------------\n",
      "20000 0.228675966155957\n",
      "HITTING EXCEPTION\n",
      "14.37059497833252\n",
      "306.5715458393097\n",
      "-----------------------------\n",
      "21000 0.24010976446375487\n",
      "HITTING EXCEPTION\n",
      "15.23104977607727\n",
      "322.33841490745544\n",
      "-----------------------------\n",
      "22000 0.2515435627715527\n",
      "HITTING EXCEPTION\n",
      "16.541980981826782\n",
      "339.4874849319458\n",
      "-----------------------------\n",
      "23000 0.26297736107935055\n",
      "HITTING EXCEPTION\n",
      "16.487430810928345\n",
      "356.7865900993347\n",
      "-----------------------------\n",
      "24000 0.2744111593871484\n",
      "HITTING EXCEPTION\n",
      "13.487383604049683\n",
      "370.71507692337036\n",
      "-----------------------------\n",
      "25000 0.2858449576949463\n",
      "HITTING EXCEPTION\n",
      "16.16484498977661\n",
      "387.36530900001526\n",
      "-----------------------------\n",
      "26000 0.2972787560027441\n",
      "HITTING EXCEPTION\n",
      "17.011390924453735\n",
      "404.98041105270386\n",
      "-----------------------------\n",
      "27000 0.30871255431054195\n",
      "HITTING EXCEPTION\n",
      "15.83120608329773\n",
      "421.4253890514374\n",
      "-----------------------------\n",
      "28000 0.3201463526183398\n",
      "HITTING EXCEPTION\n",
      "16.08355712890625\n",
      "438.0351791381836\n",
      "-----------------------------\n",
      "29000 0.3315801509261377\n",
      "HITTING EXCEPTION\n",
      "16.078562021255493\n",
      "454.6976761817932\n",
      "-----------------------------\n",
      "30000 0.3430139492339355\n",
      "HITTING EXCEPTION\n",
      "16.380783081054688\n",
      "471.63474202156067\n",
      "-----------------------------\n",
      "31000 0.35444774754173336\n",
      "HITTING EXCEPTION\n",
      "15.94306206703186\n",
      "488.1214039325714\n",
      "-----------------------------\n",
      "32000 0.3658815458495312\n",
      "HITTING EXCEPTION\n",
      "15.98713493347168\n",
      "504.6974401473999\n",
      "-----------------------------\n",
      "33000 0.3773153441573291\n",
      "HITTING EXCEPTION\n",
      "16.511690855026245\n",
      "521.823765039444\n",
      "-----------------------------\n",
      "34000 0.38874914246512693\n",
      "HITTING EXCEPTION\n",
      "14.413865804672241\n",
      "536.802414894104\n",
      "-----------------------------\n",
      "35000 0.40018294077292477\n",
      "HITTING EXCEPTION\n",
      "12.715512037277222\n",
      "549.9457001686096\n",
      "-----------------------------\n",
      "36000 0.4116167390807226\n",
      "HITTING EXCEPTION\n",
      "12.412035942077637\n",
      "562.7887420654297\n",
      "-----------------------------\n",
      "37000 0.42305053738852044\n",
      "HITTING EXCEPTION\n",
      "12.320528984069824\n",
      "575.6099810600281\n",
      "-----------------------------\n",
      "38000 0.43448433569631834\n",
      "HITTING EXCEPTION\n",
      "12.776655912399292\n",
      "588.8946421146393\n",
      "-----------------------------\n",
      "39000 0.4459181340041162\n",
      "HITTING EXCEPTION\n",
      "12.95616102218628\n",
      "602.3582780361176\n",
      "-----------------------------\n",
      "40000 0.457351932311914\n",
      "HITTING EXCEPTION\n",
      "13.010179042816162\n",
      "615.7929601669312\n",
      "-----------------------------\n",
      "41000 0.46878573061971185\n",
      "HITTING EXCEPTION\n",
      "12.52790093421936\n",
      "628.7497799396515\n",
      "-----------------------------\n",
      "42000 0.48021952892750974\n",
      "HITTING EXCEPTION\n",
      "13.564234018325806\n",
      "642.8844470977783\n",
      "-----------------------------\n",
      "43000 0.4916533272353076\n",
      "HITTING EXCEPTION\n",
      "14.671859979629517\n",
      "658.1748051643372\n",
      "-----------------------------\n",
      "44000 0.5030871255431054\n",
      "HITTING EXCEPTION\n",
      "16.268218994140625\n",
      "674.9274079799652\n",
      "-----------------------------\n",
      "45000 0.5145209238509033\n",
      "HITTING EXCEPTION\n",
      "15.974427938461304\n",
      "691.3397059440613\n",
      "-----------------------------\n",
      "46000 0.5259547221587011\n",
      "HITTING EXCEPTION\n",
      "14.3560791015625\n",
      "706.2749121189117\n",
      "-----------------------------\n",
      "47000 0.537388520466499\n",
      "HITTING EXCEPTION\n",
      "15.646278858184814\n",
      "722.5183529853821\n",
      "-----------------------------\n",
      "48000 0.5488223187742968\n",
      "HITTING EXCEPTION\n",
      "13.79568099975586\n",
      "736.8748970031738\n",
      "-----------------------------\n",
      "49000 0.5602561170820947\n",
      "HITTING EXCEPTION\n",
      "12.904461145401001\n",
      "750.2111492156982\n",
      "-----------------------------\n",
      "50000 0.5716899153898926\n",
      "HITTING EXCEPTION\n",
      "13.396406173706055\n",
      "764.04438829422\n",
      "-----------------------------\n",
      "51000 0.5831237136976903\n",
      "HITTING EXCEPTION\n",
      "13.203015089035034\n",
      "777.7131788730621\n",
      "-----------------------------\n",
      "52000 0.5945575120054882\n",
      "HITTING EXCEPTION\n",
      "12.711385726928711\n",
      "790.9539070129395\n",
      "-----------------------------\n",
      "53000 0.6059913103132861\n",
      "HITTING EXCEPTION\n",
      "12.249577045440674\n",
      "803.6827871799469\n",
      "-----------------------------\n",
      "54000 0.6174251086210839\n",
      "HITTING EXCEPTION\n",
      "12.661362171173096\n",
      "816.7873392105103\n",
      "-----------------------------\n",
      "55000 0.6288589069288818\n",
      "HITTING EXCEPTION\n",
      "13.22853398323059\n",
      "830.4460351467133\n",
      "-----------------------------\n",
      "56000 0.6402927052366796\n",
      "HITTING EXCEPTION\n",
      "12.881207704544067\n",
      "843.7489109039307\n",
      "-----------------------------\n",
      "57000 0.6517265035444775\n",
      "HITTING EXCEPTION\n",
      "12.430372953414917\n",
      "856.612016916275\n",
      "-----------------------------\n",
      "58000 0.6631603018522754\n",
      "HITTING EXCEPTION\n",
      "12.674463987350464\n",
      "869.7993459701538\n",
      "-----------------------------\n",
      "59000 0.6745941001600732\n",
      "HITTING EXCEPTION\n",
      "12.818025827407837\n",
      "883.1272089481354\n",
      "-----------------------------\n",
      "60000 0.686027898467871\n",
      "HITTING EXCEPTION\n",
      "12.937747240066528\n",
      "896.525698184967\n",
      "-----------------------------\n",
      "61000 0.6974616967756688\n",
      "HITTING EXCEPTION\n",
      "13.848514080047607\n",
      "910.840222120285\n",
      "-----------------------------\n",
      "62000 0.7088954950834667\n",
      "HITTING EXCEPTION\n",
      "12.971404075622559\n",
      "924.3307771682739\n",
      "-----------------------------\n",
      "63000 0.7203292933912646\n",
      "HITTING EXCEPTION\n",
      "12.88080382347107\n",
      "937.7089130878448\n",
      "-----------------------------\n",
      "64000 0.7317630916990624\n",
      "HITTING EXCEPTION\n",
      "12.56674313545227\n",
      "950.7162210941315\n",
      "-----------------------------\n",
      "65000 0.7431968900068603\n",
      "HITTING EXCEPTION\n",
      "12.76782488822937\n",
      "963.9969370365143\n",
      "-----------------------------\n",
      "66000 0.7546306883146582\n",
      "HITTING EXCEPTION\n",
      "14.46108102798462\n",
      "978.91823387146\n",
      "-----------------------------\n",
      "67000 0.766064486622456\n",
      "HITTING EXCEPTION\n",
      "14.906656980514526\n",
      "994.3017930984497\n",
      "-----------------------------\n",
      "68000 0.7774982849302539\n",
      "HITTING EXCEPTION\n",
      "16.83268976211548\n",
      "1011.7471199035645\n",
      "-----------------------------\n",
      "69000 0.7889320832380516\n",
      "HITTING EXCEPTION\n",
      "13.653912782669067\n",
      "1025.9880149364471\n",
      "-----------------------------\n",
      "70000 0.8003658815458495\n",
      "HITTING EXCEPTION\n",
      "13.063878059387207\n",
      "1039.5304861068726\n",
      "-----------------------------\n",
      "71000 0.8117996798536474\n",
      "HITTING EXCEPTION\n",
      "13.568952083587646\n",
      "1053.5340280532837\n",
      "-----------------------------\n",
      "72000 0.8232334781614452\n",
      "HITTING EXCEPTION\n",
      "13.979189157485962\n",
      "1068.087844133377\n",
      "-----------------------------\n",
      "73000 0.8346672764692431\n",
      "HITTING EXCEPTION\n",
      "13.999827146530151\n",
      "1082.555097103119\n",
      "-----------------------------\n",
      "74000 0.8461010747770409\n",
      "HITTING EXCEPTION\n",
      "15.419363021850586\n",
      "1098.500776052475\n",
      "-----------------------------\n",
      "75000 0.8575348730848388\n",
      "HITTING EXCEPTION\n",
      "18.36872911453247\n",
      "1117.5027220249176\n",
      "-----------------------------\n",
      "76000 0.8689686713926367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITTING EXCEPTION\n",
      "16.76389789581299\n",
      "1134.965488910675\n",
      "-----------------------------\n",
      "77000 0.8804024697004345\n",
      "HITTING EXCEPTION\n",
      "16.038021087646484\n",
      "1151.5856230258942\n",
      "-----------------------------\n",
      "78000 0.8918362680082323\n",
      "HITTING EXCEPTION\n",
      "16.997484922409058\n",
      "1169.1359241008759\n",
      "-----------------------------\n",
      "79000 0.9032700663160302\n",
      "HITTING EXCEPTION\n",
      "17.437711000442505\n",
      "1187.1217081546783\n",
      "-----------------------------\n",
      "80000 0.914703864623828\n",
      "HITTING EXCEPTION\n",
      "17.101939916610718\n",
      "1204.7873649597168\n",
      "-----------------------------\n",
      "81000 0.9261376629316259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/kn/lib/python3.7/site-packages/ipykernel_launcher.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.7082998752594\n",
      "1229.0669379234314\n",
      "-----------------------------\n",
      "82000 0.9375714612394237\n",
      "HITTING EXCEPTION\n",
      "39.07377576828003\n",
      "1268.7593240737915\n",
      "-----------------------------\n",
      "83000 0.9490052595472216\n",
      "41.15055799484253\n",
      "1310.3511009216309\n",
      "-----------------------------\n",
      "84000 0.9604390578550195\n",
      "HITTING EXCEPTION\n",
      "40.704740047454834\n",
      "1351.5636150836945\n",
      "-----------------------------\n",
      "85000 0.9718728561628173\n",
      "37.98360991477966\n",
      "1389.9659259319305\n",
      "-----------------------------\n",
      "86000 0.9833066544706152\n",
      "HITTING EXCEPTION\n",
      "43.664883852005005\n",
      "1434.0643610954285\n",
      "-----------------------------\n",
      "87000 0.9947404527784129\n",
      "HITTING EXCEPTION\n",
      "42.60224771499634\n",
      "1477.2113211154938\n",
      "-----------------------------\n",
      "87460 1.0\n",
      "HITTING EXCEPTION\n",
      "18.859694957733154\n",
      "1496.2873170375824\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "log = {}\n",
    "log['securitization'] = term\n",
    "master_list = []\n",
    "broke = 0\n",
    "cautions = 0\n",
    "status = 'good'\n",
    "s1 = time.time()\n",
    "ids_count = 0\n",
    "for ids in id_lists:\n",
    "    \n",
    "    # get update\n",
    "    ids_count = ids_count + len(ids)\n",
    "    percent = ids_count / len(all_ids)\n",
    "    print(ids_count, percent)\n",
    "    \n",
    "    # create sub\n",
    "    sub_df = data[data[id_col].isin(ids)]\n",
    "    sub_df['indexTransaction'] = sub_df.index\n",
    "    sub_df = sub_df.reset_index(drop = True)\n",
    "    splits = list(sub_df.groupby(id_col)) \n",
    "    l = [splits[n_][1] for n_ in list(range(len(splits)))]\n",
    "    a = np.array(l)\n",
    "    \n",
    "    # get results\n",
    "    s2 = time.time()\n",
    "    try:\n",
    "        exception_status = False\n",
    "        results = [convert_static(d, exception_status) for d in a]\n",
    "        for r in results:\n",
    "            master_list.append(r)\n",
    "    except:\n",
    "        try:\n",
    "            exception_status = True \n",
    "            cautions = cautions + 1\n",
    "            print('HITTING EXCEPTION')\n",
    "            for l2 in l:\n",
    "                res = convert_static(l2, exception_status)\n",
    "                master_list.append(res)\n",
    "        except:\n",
    "            status = 'bad'\n",
    "            broke = broke + 1\n",
    "            if broke > 0:\n",
    "                sys.exit('Too many errors...')\n",
    "    \n",
    "    e1 = time.time()\n",
    "    e2 = time.time()\n",
    "    log['{}'.format(ids_count)] = (e2 - s2)\n",
    "    \n",
    "    print(e2 - s2)\n",
    "    print(e1 - s1)\n",
    "    print('-----------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "log['total_time'] = e1 - s1\n",
    "log['run_status'] = status\n",
    "log['cautions'] = cautions\n",
    "log['duplicate_rows'] = dup_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.DataFrame(master_list)\n",
    "log['loans'] = len(master)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = master['obligorCreditScoreLocCurrent'].mean()\n",
    "if cs <= 620:\n",
    "    rating = 'sub_prime'\n",
    "elif cs > 620 and cs <= 720:\n",
    "    rating = 'near_prime'\n",
    "elif cs > 720:\n",
    "    rating = 'prime'\n",
    "else:\n",
    "    rating = 'other'\n",
    "log['average_credit'] = cs\n",
    "log['rating'] = rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_ids) == len(master_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                        78861\n",
       "Prepaid or Matured         8556 \n",
       "Charged-off                42   \n",
       "Repurchased or Replaced    1    \n",
       "Name: accountStatusEvent, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master['accountStatusEvent'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding final fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['securitization'] = term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(row):\n",
    "    \n",
    "    \"\"\"\n",
    "    Set target var\n",
    "    \"\"\"\n",
    "    \n",
    "    init = str(row['accountStatusEvent'])\n",
    "    remaining = row['remainingTermToMaturityNumberMinPrior']\n",
    "    #remaining = row['remainingTermToMaturityNumberLocCurrent']\n",
    "    #remaining = row['remainingTermToMaturityNumberLocPrior']\n",
    "    \n",
    "    if init == 'Charged-off':\n",
    "        res = 'Charged-off'\n",
    "        return res\n",
    "    elif init == 'Prepaid or Matured' and remaining > 1:\n",
    "        res = 'Prepaid'\n",
    "        return res\n",
    "    elif init == 'Prepaid or Matured' and remaining < 2:\n",
    "        res = 'Closed'\n",
    "        return res\n",
    "    elif init == 'nan':\n",
    "        res = 'Active or other'\n",
    "        return res\n",
    "    else:\n",
    "        res = 'Active or other'\n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['target'] = master.apply(get_target, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Active or other    78862\n",
       "Prepaid            7730 \n",
       "Closed             826  \n",
       "Charged-off        42   \n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master['target'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_regions(state):\n",
    "    \n",
    "    \"\"\"\n",
    "    Get region\n",
    "    \"\"\"\n",
    "    \n",
    "    if state in west:\n",
    "        return 'West'\n",
    "    elif state in south_west:\n",
    "        return 'SouthWest'\n",
    "    elif state in south_east:\n",
    "        return 'SouthEast'\n",
    "    elif state in mid_west:\n",
    "        return 'MidWest'\n",
    "    elif state in north_east:\n",
    "        return 'NorthEast'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['region'] = np.nan\n",
    "    \n",
    "master['region'] = master['obligorGeographicLocationLocCurrent'].apply(finding_regions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_year(init):\n",
    "    \n",
    "    \"\"\"\n",
    "    Get origination year\n",
    "    \"\"\"\n",
    "    \n",
    "    year = init[0:4]\n",
    "    \n",
    "    return year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_col = 'originationDateRLocCurrent'\n",
    "\n",
    "year_vals = master[year_col].values\n",
    "years = [get_or_year(y) for y in year_vals]\n",
    "master['originationYear'] = years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['originationDate'] = pd.to_datetime(master['originationDateRLocCurrent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87460, 713)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#master[master['exceptionStatus'].isin([True])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding outcome for transaction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_col = 'id'\n",
    "m_type = 'left'\n",
    "merged = pd.merge(data, master[[m_col, 'target']], on = m_col, how = m_type)\n",
    "ft_shape = merged.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422950"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bool = init_shape == sec_shape == ft_shape\n",
    "log['lengths_match'] = final_bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vals cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_cols = [col for col in list(master.columns) if 'vals' in col.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_vals(row, column):\n",
    "\n",
    "    \"\"\"\n",
    "    Fix column values\n",
    "    \"\"\"\n",
    "\n",
    "    init = str(row[column])\n",
    "\n",
    "    ret_val = 'str: ' + init\n",
    "\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obligorIncomeVerificationLevelCodeValsCurrent\n",
      "interestCalculationTypeCodeValsCurrent\n",
      "zeroBalanceCodeValsCurrent\n",
      "subventedValsCurrent\n",
      "modificationTypeCodeValsCurrent\n",
      "assetSubjectDemandStatusCodeValsCurrent\n",
      "repurchaseReplacementReasonCodeValsCurrent\n",
      "vehicleValueSourceCodeValsCurrent\n",
      "accountStatusValsCurrent\n",
      "obligorEmploymentVerificationCodeValsCurrent\n",
      "originalInterestRateTypeCodeValsCurrent\n",
      "vehicleNewUsedCodeValsCurrent\n",
      "vehicleTypeCodeValsCurrent\n",
      "paymentTypeCodeValsCurrent\n",
      "indexAccountValsCurrent\n",
      "servicingAdvanceMethodCodeValsCurrent\n",
      "indexTransactionValsCurrent\n",
      "zeroBalanceCodeMValsCurrent\n",
      "obligorIncomeVerificationLevelCodeValsPrior\n",
      "interestCalculationTypeCodeValsPrior\n",
      "zeroBalanceCodeValsPrior\n",
      "subventedValsPrior\n",
      "modificationTypeCodeValsPrior\n",
      "assetSubjectDemandStatusCodeValsPrior\n",
      "repurchaseReplacementReasonCodeValsPrior\n",
      "vehicleValueSourceCodeValsPrior\n",
      "accountStatusValsPrior\n",
      "obligorEmploymentVerificationCodeValsPrior\n",
      "originalInterestRateTypeCodeValsPrior\n",
      "vehicleNewUsedCodeValsPrior\n",
      "vehicleTypeCodeValsPrior\n",
      "paymentTypeCodeValsPrior\n",
      "indexAccountValsPrior\n",
      "servicingAdvanceMethodCodeValsPrior\n",
      "indexTransactionValsPrior\n",
      "zeroBalanceCodeMValsPrior\n",
      "obligorIncomeVerificationLevelCodeValsRandom\n",
      "interestCalculationTypeCodeValsRandom\n",
      "zeroBalanceCodeValsRandom\n",
      "subventedValsRandom\n",
      "modificationTypeCodeValsRandom\n",
      "assetSubjectDemandStatusCodeValsRandom\n",
      "repurchaseReplacementReasonCodeValsRandom\n",
      "vehicleValueSourceCodeValsRandom\n",
      "accountStatusValsRandom\n",
      "obligorEmploymentVerificationCodeValsRandom\n",
      "originalInterestRateTypeCodeValsRandom\n",
      "vehicleNewUsedCodeValsRandom\n",
      "vehicleTypeCodeValsRandom\n",
      "paymentTypeCodeValsRandom\n",
      "indexAccountValsRandom\n",
      "servicingAdvanceMethodCodeValsRandom\n",
      "indexTransactionValsRandom\n",
      "zeroBalanceCodeMValsRandom\n"
     ]
    }
   ],
   "source": [
    "for col in vals_cols:\n",
    "    print(col)\n",
    "    master[col] = master[col].astype(str)\n",
    "    master[col] = 'str: ' + master[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/karus_datasets/Toyota/Toyota 2020-D/'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_folder = 'data/karus_datasets/{}/{} {}/'.format(originator, originator, add_id)\n",
    "export_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_bool = os.path.isdir(export_folder)\n",
    "path_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir exists\n"
     ]
    }
   ],
   "source": [
    "if path_bool == False:\n",
    "    os.mkir(export_folder)\n",
    "    print('dir folder')\n",
    "else:\n",
    "    print('dir exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/karus_datasets/Toyota/Toyota 2020-D/static.csv\n",
      "(87460, 713)\n"
     ]
    }
   ],
   "source": [
    "#e_folder = 'data/static/'\n",
    "e_file = 'static.csv'.format(add_id)\n",
    "e_path = export_folder + e_file\n",
    "print(e_path)\n",
    "print(master.shape)\n",
    "master.to_csv(e_path, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/karus_datasets/Toyota/Toyota 2020-D/transaction.csv\n",
      "(422950, 99)\n"
     ]
    }
   ],
   "source": [
    "#t_folder = 'data/transaction/prepared/'\n",
    "t_file = 'transaction.csv'.format(add_id)\n",
    "t_path = export_folder + t_file\n",
    "print(t_path)\n",
    "print(merged.shape)\n",
    "merged.to_csv(t_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export log\n",
    "#j_folder = 'data/static/log/'\n",
    "j_file = '{} log.json'.format(term)\n",
    "j_path = export_folder + j_file\n",
    "with open(j_path, 'w') as outfile:  \n",
    "    json.dump(log, outfile, indent = 4, separators = (',', ': '), sort_keys = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue...\n"
     ]
    }
   ],
   "source": [
    "print('continue...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
