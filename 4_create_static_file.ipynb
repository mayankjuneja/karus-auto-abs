{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 12 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from pandarallel import pandarallel\n",
    "import re\n",
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "import os\n",
    "\n",
    "pandarallel.initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/kn/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "n = 750\n",
    "pd.set_option('display.max_columns', n)\n",
    "pd.set_option('display.max_rows', n)\n",
    "pd.set_option('display.max_colwidth', -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "originator = 'Santander'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term = 'Santander Drive Auto Receivables Trust 2017-1 Data Tape'\n",
    "finder = re.compile('\\d{4,}\\W\\d{1,}')\n",
    "add_id = re.findall(finder, term)[0]\n",
    "add_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/kn/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (17,66,67) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2178828, 73)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load abs\n",
    "folder = 'data/transaction/'\n",
    "file = '{}.csv'.format(term)\n",
    "path = folder + file\n",
    "data = pd.read_csv(path)\n",
    "init_shape = data.shape[0]\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fields\n",
    "f_folder = 'data/json/fields/'\n",
    "f_file = 'fields.json'\n",
    "f_path = f_folder + f_file\n",
    "with open(f_path) as f:\n",
    "    fields = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mapper\n",
    "m_folder = 'data/dictionary/mapper/'\n",
    "m_file = 'mapper.json'\n",
    "m_path = m_folder + m_file\n",
    "with open(m_path) as f:\n",
    "    mapper = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_id = fields['init_id'][0]\n",
    "date_cols = fields['dates']\n",
    "replacer_cols = fields['replace_dash']\n",
    "clean_cols = fields['clean']\n",
    "m_cols = fields['map']\n",
    "event_cols = fields['event']\n",
    "loc_cols = fields['all_loc']\n",
    "numeric_cols = fields['numeric']\n",
    "all_vals_cols = fields['all_vals']\n",
    "min_max_cols = fields['min_max']\n",
    "west = fields['regions']['west']\n",
    "south_west = fields['regions']['south_west']\n",
    "south_east = fields['regions']['south_east']\n",
    "mid_west = fields['regions']['mid_west']\n",
    "north_east = fields['regions']['north_east']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID and dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_date(init):\n",
    "    \n",
    "    \"\"\"\n",
    "    Reorder date\n",
    "    \"\"\"\n",
    "    \n",
    "    init = str(init)\n",
    "    if init != '-':\n",
    "        if '/' not in init:\n",
    "            y = init[6:10]\n",
    "            m = init[0:2]\n",
    "            d = init[3:5]\n",
    "            date = y + '-' + m + '-' + d\n",
    "        elif '/' in init:\n",
    "            y = init[3:7]\n",
    "            m = init[0:2]\n",
    "            date = y + '-' + m\n",
    "    else:\n",
    "        date = ''\n",
    "    \n",
    "    return date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['id'] = data[init_id].str.replace('=', '').str.replace('\"', '').str.strip() + '-' + add_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reportingPeriodBeginningDate\n",
      "DemandResolutionDate\n",
      "reportingPeriodEndingDate\n",
      "loanMaturityDate\n",
      "originationDate\n",
      "interestPaidThroughDate\n",
      "originalFirstPaymentDate\n",
      "mostRecentServicingTransferReceivedDate\n",
      "zeroBalanceEffectiveDate\n"
     ]
    }
   ],
   "source": [
    "for col in date_cols:\n",
    "    print(col)\n",
    "    values = data[col].values\n",
    "    dates = [reorder_date(v) for v in values]\n",
    "    data['{}R'.format(col)] = dates\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2178828, 83)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sort_values(by=['reportingPeriodBeginningDateR'], ascending=False)\n",
    "data = data.drop_duplicates(subset = ['id', 'reportingPeriodBeginningDateR'], keep = 'first')\n",
    "sec_shape = data.shape[0]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching shapes\n"
     ]
    }
   ],
   "source": [
    "if init_shape == sec_shape:\n",
    "    dup_rows = False\n",
    "    print('Matching shapes')\n",
    "else:\n",
    "    dup_rows = True \n",
    "    print('Duplicate rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_col = 'loanMaturityDate'\n",
    "# t_col = '{}R'.format(s_col)\n",
    "# data[[s_col, t_col]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[replacer_cols] = data[replacer_cols].replace('-', np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean cols\n",
    "for col in clean_cols:\n",
    "    data[col] = data[col].astype(str)\n",
    "    data[col] = data[col].str.strip()\n",
    "    data[col] = data[col].astype(float)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_val(init, column):\n",
    "    \n",
    "    \"\"\"\n",
    "    Replace numeric values\n",
    "    \"\"\"\n",
    "    \n",
    "    init = str(init).strip().replace(';', '')\n",
    "    if init in ['0', '1', '2', '3', '4', '5', '98', '99']:\n",
    "        mapped = mapper[column][init]\n",
    "        return mapped\n",
    "    else:\n",
    "        if init[0] in ['0', '1', '2', '3', '4', '5']:\n",
    "            use = init[0]\n",
    "        elif init == '-':\n",
    "            use_keys = list(mapper[column].keys())\n",
    "            if '98' in use_keys:\n",
    "                use = '98'\n",
    "            elif '99' in use_keys:\n",
    "                use = '99'\n",
    "        else:\n",
    "            use = init\n",
    "        mapped = mapper[column][use]\n",
    "        \n",
    "    return mapped\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obligorIncomeVerificationLevelCode\n",
      "interestCalculationTypeCode\n",
      "zeroBalanceCode\n",
      "modificationTypeCode\n",
      "assetSubjectDemandStatusCode\n",
      "repurchaseReplacementReasonCode\n",
      "vehicleValueSourceCode\n",
      "obligorEmploymentVerificationCode\n",
      "vehicleNewUsedCode\n",
      "vehicleTypeCode\n",
      "paymentTypeCode\n",
      "servicingAdvanceMethodCode\n",
      "originalInterestRateTypeCode\n",
      "subvented\n"
     ]
    }
   ],
   "source": [
    "for col in m_cols:\n",
    "    print(col)\n",
    "    values = data[col].values\n",
    "    ret_vals = [replace_val(v, col) for v in values]\n",
    "    data['{}M'.format(col)] = ret_vals\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_col = 'subvented'\n",
    "# t_col = '{}M'.format(s_col)\n",
    "# data[[s_col, t_col]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Account status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acct_status(row, b_col, e_col, zero_col, thresh):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create karus account status\n",
    "    \"\"\"\n",
    "    \n",
    "    b = float(row[b_col])\n",
    "    e = float(row[e_col])\n",
    "    z = str(row[zero_col])\n",
    "    \n",
    "    if z in ['Charged-off', 'Repurchased or Replaced']:\n",
    "        res = z\n",
    "        return res\n",
    "    if b < thresh and e < thresh:\n",
    "        res = 'Prepaid or Matured'\n",
    "        return res\n",
    "    if z in ['Unavailable', 'Prepaid or Matured']:\n",
    "        res = z\n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_col = 'reportingPeriodBeginningLoanBalanceAmount'\n",
    "e_col = 'nextReportingPeriodPaymentAmountDue'\n",
    "z_col = 'zeroBalanceCodeM'\n",
    "thresh = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['accountStatus'] = data.parallel_apply(acct_status, args = (b_col, e_col, z_col, thresh, ), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unavailable                1860969\n",
       "Charged-off                280152 \n",
       "Prepaid or Matured         33457  \n",
       "Repurchased or Replaced    4250   \n",
       "Name: accountStatus, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['accountStatus'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currentDelinquencyStatus\n",
      "paymentToIncomePercentage\n",
      "paymentExtendedNumber\n",
      "otherAssessedUncollectedServicerFeeAmount\n",
      "totalActualAmountPaid\n",
      "actualInterestCollectedAmount\n",
      "remainingTermToMaturityNumber\n",
      "reportingPeriodScheduledPaymentAmount\n",
      "vehicleValueAmount\n",
      "reportingPeriodInterestRatePercentage\n",
      "scheduledInterestAmount\n",
      "actualPrincipalCollectedAmount\n",
      "actualOtherCollectedAmount\n",
      "reportingPeriodActualEndBalanceAmount\n",
      "servicingFlatFeeAmount\n",
      "chargedoffPrincipalAmount\n",
      "servicingFeePercentage\n",
      "otherPrincipalAdjustmentAmount\n",
      "obligorCreditScore\n",
      "originalInterestRatePercentage\n",
      "nextReportingPeriodPaymentAmountDue\n",
      "gracePeriodNumber\n",
      "originalLoanTerm\n",
      "repurchaseAmount\n",
      "recoveredAmount\n",
      "servicerAdvancedAmount\n",
      "originalLoanAmount\n",
      "repossessedProceedsAmount\n",
      "nextInterestRatePercentage\n",
      "scheduledPrincipalAmount\n",
      "reportingPeriodBeginningLoanBalanceAmount\n"
     ]
    }
   ],
   "source": [
    "# force convert cols to numeric\n",
    "for col in numeric_cols:\n",
    "    print(col)\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = 'id'\n",
    "status_col = 'accountStatus'\n",
    "values = ['Charged-off', 'Prepaid or Matured', 'Repurchased or Replaced']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66797"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = list(data[id_col].unique())\n",
    "#all_ids = all_ids[:1000]\n",
    "print_vals = list(range(0, len(all_ids), 100))\n",
    "len(all_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break ids into list chunks\n",
    "num = 1000\n",
    "id_lists = [all_ids[i:i + num] for i in range(0, len(all_ids), num)]  \n",
    "#id_lists = [id_lists[-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_static(df, exception_status):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create static df\n",
    "    \"\"\"\n",
    "    \n",
    "    #df = init.reset_values(drop = True)\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    df = df.sort_values('reportingPeriodBeginningDateR', ascending = False)\n",
    "    df['indexAccount'] = df.index\n",
    "    _id = df[id_col].iloc[0]\n",
    "\n",
    "    # dict\n",
    "    account_dict = {}\n",
    "    account_dict['exceptionStatus'] = exception_status\n",
    "    account_dict[id_col] = _id\n",
    "    account_dict['records'] = len(df)\n",
    "\n",
    "    # current status of loan\n",
    "    for col in loc_cols:\n",
    "        account_dict['{}LocCurrent'.format(col)] = df[col].iloc[0]\n",
    "    for col in min_max_cols:\n",
    "        account_dict['{}MaxCurrent'.format(col)] = df[col].max()\n",
    "        account_dict['{}MinCurrent'.format(col)] = df[col].min()\n",
    "    for col in all_vals_cols:\n",
    "        vals = list(df[col].unique())\n",
    "        use_vals = ' | '.join(str(val) for val in vals)\n",
    "        account_dict['{}ValsCurrent'.format(col)] = use_vals\n",
    "    for col in numeric_cols:\n",
    "        _sum = df[col].sum()\n",
    "        account_dict['{}SumCurrent'.format(col)] = _sum\n",
    "        vec = list(df[col])\n",
    "        vec = [v for v in vec if str(v) != 'nan']\n",
    "        if len(vec) > 0:\n",
    "            _len = len(vec)\n",
    "            weights = sorted([1 + i for i in list(range(_len))], reverse=True)\n",
    "            wa = np.average(vec, weights=weights)\n",
    "            account_dict['{}WeightedCurrent'.format(col)] = wa\n",
    "        else:\n",
    "            account_dict['{}WeightedCurrent'.format(col)] = 0\n",
    "\n",
    "    # event information\n",
    "    init_vals = list(df[status_col].unique())\n",
    "    inter = list(set(values).intersection(init_vals))\n",
    "    if len(inter) > 0:\n",
    "        account_dict['eventOccurred'] = 1\n",
    "        n = df[status_col].where(df[status_col].isin(values)).last_valid_index()\n",
    "        account_dict['eventIndex'] = n\n",
    "        n_bool = True\n",
    "        single = df.loc[[n]]\n",
    "        for col in event_cols:\n",
    "            account_dict['{}Event'.format(col)] = single[col].iloc[0]\n",
    "\n",
    "        # prior to event\n",
    "        init = n+1\n",
    "        sub = df[init:len(df)]\n",
    "        sub.reset_index(drop = True, inplace = True)\n",
    "        account_dict['priorHistory'] = len(sub)\n",
    "        sub_bool = True\n",
    "        if len(sub) > 0:\n",
    "            for col in loc_cols:\n",
    "                account_dict['{}LocPrior'.format(col)] = sub[col].iloc[0]\n",
    "            for col in min_max_cols:\n",
    "                account_dict['{}MinPrior'.format(col)] = sub[col].min()\n",
    "                account_dict['{}MaxPrior'.format(col)] = sub[col].max()\n",
    "            for col in all_vals_cols:\n",
    "                vals = list(sub[col].unique())\n",
    "                use_vals = ' | '.join(str(val) for val in vals)\n",
    "                account_dict['{}ValsPrior'.format(col)] = use_vals\n",
    "            for col in numeric_cols:\n",
    "                account_dict['{}SumPrior'.format(col)] = sub[col].sum()\n",
    "                vec = list(sub[col])\n",
    "                vec = [v for v in vec if str(v) != 'nan']\n",
    "                if len(vec) > 0:\n",
    "                    _len = len(vec)\n",
    "                    weights = sorted([1 + i for i in list(range(_len))], reverse=True)\n",
    "                    wa = np.average(vec, weights=weights)\n",
    "                    account_dict['{}WeightedPrior'.format(col)] = wa\n",
    "                else:\n",
    "                    account_dict['{}WeightedPrior'.format(col)] = 0\n",
    "\n",
    "            # random\n",
    "            len_sub = len(sub)            \n",
    "            s = random.randint(0, len_sub)\n",
    "            if s == len_sub:\n",
    "                s = s -1\n",
    "            r_sub = sub[s:len_sub].reset_index(drop = True)\n",
    "            account_dict['randomIndex'] = s\n",
    "            for col in loc_cols:\n",
    "                account_dict['{}LocRandom'.format(col)] = r_sub[col].iloc[0]\n",
    "            for col in min_max_cols:\n",
    "                account_dict['{}MinRandom'.format(col)] = r_sub[col].min()\n",
    "                account_dict['{}MaxRandom'.format(col)] = r_sub[col].max()\n",
    "            for col in all_vals_cols:\n",
    "                vals = list(r_sub[col].unique())\n",
    "                use_vals = ' | '.join(str(val) for val in vals)\n",
    "                account_dict['{}ValsRandom'.format(col)] = use_vals\n",
    "            for col in numeric_cols:\n",
    "                account_dict['{}SumRandom'.format(col)] = r_sub[col].sum()\n",
    "                vec = list(r_sub[col])\n",
    "                vec = [v for v in vec if str(v) != 'nan']\n",
    "                if len(vec) > 0:\n",
    "                    _len = len(vec)\n",
    "                    weights = sorted([1 + i for i in list(range(_len))], reverse=True)\n",
    "                    wa = np.average(vec, weights=weights)\n",
    "                    account_dict['{}WeightedRandom'.format(col)] = wa\n",
    "                else:\n",
    "                    account_dict['{}WeightedRandom'.format(col)] = 0\n",
    "\n",
    "        # if event is first row of sub       \n",
    "        else:\n",
    "            for col in loc_cols:\n",
    "                account_dict['{}LocPrior'.format(col)] = df[col].iloc[0]\n",
    "            for col in min_max_cols:\n",
    "                account_dict['{}MinPrior'.format(col)] = df[col].min()\n",
    "                account_dict['{}MaxPrior'.format(col)] = df[col].max()\n",
    "            for col in all_vals_cols:\n",
    "                vals = list(df[col].unique())\n",
    "                use_vals = ' | '.join(str(val) for val in vals)\n",
    "                account_dict['{}ValsPrior'.format(col)] = use_vals\n",
    "            for col in numeric_cols:\n",
    "                account_dict['{}SumPrior'.format(col)] = df[col].sum()\n",
    "                account_dict['{}WeightedPrior'.format(col)] = df[col].iloc[0]\n",
    "\n",
    "    # if no event        \n",
    "    else:\n",
    "        account_dict['eventOccurred'] = 0\n",
    "        account_dict['priorHistory'] = len(df)\n",
    "        sub_bool = False\n",
    "        n_bool = False\n",
    "        for col in event_cols:\n",
    "            account_dict['{}Event'.format(col)] = np.nan\n",
    "        for col in loc_cols:\n",
    "            account_dict['{}LocPrior'.format(col)] = np.nan\n",
    "        for col in min_max_cols:\n",
    "            account_dict['{}MinPrior'.format(col)] = np.nan\n",
    "            account_dict['{}MaxPrior'.format(col)] = np.nan\n",
    "        for col in all_vals_cols:\n",
    "            account_dict['{}ValsPrior'.format(col)] = np.nan\n",
    "        for col in numeric_cols:\n",
    "            account_dict['{}SumPrior'.format(col)] = np.nan\n",
    "            account_dict['{}WeightedPrior'.format(col)] = np.nan\n",
    "\n",
    "        # random set to nan\n",
    "        account_dict['randomIndex'] = np.nan\n",
    "        for col in loc_cols:\n",
    "            account_dict['{}LocRandom'.format(col)] = np.nan\n",
    "        for col in min_max_cols:\n",
    "            account_dict['{}MinRandom'.format(col)] = np.nan\n",
    "            account_dict['{}MaxRandom'.format(col)] = np.nan\n",
    "        for col in all_vals_cols:\n",
    "            account_dict['{}ValsRandom'.format(col)] = np.nan\n",
    "        for col in numeric_cols:\n",
    "            account_dict['{}SumRandom'.format(col)] = np.nan\n",
    "            account_dict['{}WeightedRandom'.format(col)] = np.nan\n",
    "\n",
    "    return account_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.014970732218512807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/kn/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/anaconda3/envs/kn/lib/python3.7/site-packages/ipykernel_launcher.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.476080179214478\n",
      "25.02335810661316\n",
      "-----------------------------\n",
      "2000 0.029941464437025615\n",
      "24.51812219619751\n",
      "50.38272714614868\n",
      "-----------------------------\n",
      "3000 0.044912196655538424\n",
      "HITTING EXCEPTION\n",
      "21.864840984344482\n",
      "73.22652578353882\n",
      "-----------------------------\n",
      "4000 0.05988292887405123\n",
      "21.526623010635376\n",
      "95.60423588752747\n",
      "-----------------------------\n",
      "5000 0.07485366109256404\n",
      "21.389912128448486\n",
      "117.9216821193695\n",
      "-----------------------------\n",
      "6000 0.08982439331107685\n",
      "22.15103006362915\n",
      "140.90189790725708\n",
      "-----------------------------\n",
      "7000 0.10479512552958965\n",
      "HITTING EXCEPTION\n",
      "21.20044994354248\n",
      "163.08914494514465\n",
      "-----------------------------\n",
      "8000 0.11976585774810246\n",
      "HITTING EXCEPTION\n",
      "23.681312799453735\n",
      "187.83098483085632\n",
      "-----------------------------\n",
      "9000 0.13473658996661528\n",
      "HITTING EXCEPTION\n",
      "23.603543758392334\n",
      "212.56386995315552\n",
      "-----------------------------\n",
      "10000 0.14970732218512808\n",
      "HITTING EXCEPTION\n",
      "26.35516905784607\n",
      "239.95480394363403\n",
      "-----------------------------\n",
      "11000 0.1646780544036409\n",
      "26.63949990272522\n",
      "267.5237638950348\n",
      "-----------------------------\n",
      "12000 0.1796487866221537\n",
      "30.62333583831787\n",
      "299.1756899356842\n",
      "-----------------------------\n",
      "13000 0.1946195188406665\n",
      "34.11789298057556\n",
      "334.2238550186157\n",
      "-----------------------------\n",
      "14000 0.2095902510591793\n",
      "HITTING EXCEPTION\n",
      "27.734951972961426\n",
      "363.1727659702301\n",
      "-----------------------------\n",
      "15000 0.2245609832776921\n",
      "21.730172872543335\n",
      "385.81802797317505\n",
      "-----------------------------\n",
      "16000 0.23953171549620492\n",
      "26.017714977264404\n",
      "412.63032698631287\n",
      "-----------------------------\n",
      "17000 0.25450244771471775\n",
      "26.044797897338867\n",
      "439.51000785827637\n",
      "-----------------------------\n",
      "18000 0.26947317993323056\n",
      "28.19749617576599\n",
      "468.5716950893402\n",
      "-----------------------------\n",
      "19000 0.28444391215174336\n",
      "22.480673789978027\n",
      "491.827091217041\n",
      "-----------------------------\n",
      "20000 0.29941464437025617\n",
      "HITTING EXCEPTION\n",
      "20.30185604095459\n",
      "513.02032995224\n",
      "-----------------------------\n",
      "21000 0.31438537658876897\n",
      "19.644216775894165\n",
      "533.4296839237213\n",
      "-----------------------------\n",
      "22000 0.3293561088072818\n",
      "22.070501804351807\n",
      "556.2758619785309\n",
      "-----------------------------\n",
      "23000 0.3443268410257946\n",
      "20.525711059570312\n",
      "577.6152601242065\n",
      "-----------------------------\n",
      "24000 0.3592975732443074\n",
      "HITTING EXCEPTION\n",
      "19.9719820022583\n",
      "598.5022089481354\n",
      "-----------------------------\n",
      "25000 0.3742683054628202\n",
      "32.61704611778259\n",
      "632.0101389884949\n",
      "-----------------------------\n",
      "26000 0.389239037681333\n",
      "42.669073820114136\n",
      "675.6065587997437\n",
      "-----------------------------\n",
      "27000 0.4042097698998458\n",
      "42.39872694015503\n",
      "719.0106890201569\n",
      "-----------------------------\n",
      "28000 0.4191805021183586\n",
      "41.62262201309204\n",
      "761.4863879680634\n",
      "-----------------------------\n",
      "29000 0.4341512343368714\n",
      "47.41098189353943\n",
      "809.9727280139923\n",
      "-----------------------------\n",
      "30000 0.4491219665553842\n",
      "45.26671004295349\n",
      "856.17587018013\n",
      "-----------------------------\n",
      "31000 0.464092698773897\n",
      "47.258482217788696\n",
      "904.3532991409302\n",
      "-----------------------------\n",
      "32000 0.47906343099240983\n",
      "40.916794776916504\n",
      "946.3012158870697\n",
      "-----------------------------\n",
      "33000 0.49403416321092264\n",
      "41.52364110946655\n",
      "988.7107701301575\n",
      "-----------------------------\n",
      "34000 0.5090048954294355\n",
      "39.64607214927673\n",
      "1029.1665761470795\n",
      "-----------------------------\n",
      "35000 0.5239756276479482\n",
      "39.56033182144165\n",
      "1069.6180889606476\n",
      "-----------------------------\n",
      "36000 0.5389463598664611\n",
      "38.49246096611023\n",
      "1108.878910779953\n",
      "-----------------------------\n",
      "37000 0.5539170920849739\n",
      "36.19673800468445\n",
      "1145.8758239746094\n",
      "-----------------------------\n",
      "38000 0.5688878243034867\n",
      "37.38748788833618\n",
      "1184.0489089488983\n",
      "-----------------------------\n",
      "39000 0.5838585565219995\n",
      "37.558913230895996\n",
      "1222.3131239414215\n",
      "-----------------------------\n",
      "40000 0.5988292887405123\n",
      "40.65081596374512\n",
      "1263.7433168888092\n",
      "-----------------------------\n",
      "41000 0.6138000209590251\n",
      "38.884204149246216\n",
      "1303.40061211586\n",
      "-----------------------------\n",
      "42000 0.6287707531775379\n",
      "38.8929648399353\n",
      "1343.1320099830627\n",
      "-----------------------------\n",
      "43000 0.6437414853960507\n",
      "43.32906126976013\n",
      "1387.298331975937\n",
      "-----------------------------\n",
      "44000 0.6587122176145636\n",
      "44.84133291244507\n",
      "1432.9089069366455\n",
      "-----------------------------\n",
      "45000 0.6736829498330763\n",
      "43.75888776779175\n",
      "1477.4221549034119\n",
      "-----------------------------\n",
      "46000 0.6886536820515892\n",
      "39.81099224090576\n",
      "1517.9800291061401\n",
      "-----------------------------\n",
      "47000 0.7036244142701019\n",
      "47.541378021240234\n",
      "1566.188038110733\n",
      "-----------------------------\n",
      "48000 0.7185951464886148\n",
      "49.92288684844971\n",
      "1616.9566519260406\n",
      "-----------------------------\n",
      "49000 0.7335658787071275\n",
      "50.97250699996948\n",
      "1668.7589328289032\n",
      "-----------------------------\n",
      "50000 0.7485366109256404\n",
      "51.804306983947754\n",
      "1721.4095368385315\n",
      "-----------------------------\n",
      "51000 0.7635073431441531\n",
      "43.31362509727478\n",
      "1765.5027239322662\n",
      "-----------------------------\n",
      "52000 0.778478075362666\n",
      "40.87884783744812\n",
      "1806.965276002884\n",
      "-----------------------------\n",
      "53000 0.7934488075811787\n",
      "36.22091507911682\n",
      "1843.8710670471191\n",
      "-----------------------------\n",
      "54000 0.8084195397996916\n",
      "HITTING EXCEPTION\n",
      "35.470141887664795\n",
      "1880.0073897838593\n",
      "-----------------------------\n",
      "55000 0.8233902720182044\n",
      "35.91488289833069\n",
      "1916.5036010742188\n",
      "-----------------------------\n",
      "56000 0.8383610042367172\n",
      "35.76726198196411\n",
      "1952.9115450382233\n",
      "-----------------------------\n",
      "57000 0.85333173645523\n",
      "35.8941171169281\n",
      "1989.4379680156708\n",
      "-----------------------------\n",
      "58000 0.8683024686737428\n",
      "35.88940691947937\n",
      "2025.9602069854736\n",
      "-----------------------------\n",
      "59000 0.8832732008922557\n",
      "35.959280014038086\n",
      "2062.525331020355\n",
      "-----------------------------\n",
      "60000 0.8982439331107684\n",
      "35.040589809417725\n",
      "2098.103678226471\n",
      "-----------------------------\n",
      "61000 0.9132146653292813\n",
      "36.234992027282715\n",
      "2134.9323530197144\n",
      "-----------------------------\n",
      "62000 0.928185397547794\n",
      "36.86536884307861\n",
      "2172.328852891922\n",
      "-----------------------------\n",
      "63000 0.9431561297663069\n",
      "38.356189012527466\n",
      "2211.261417865753\n",
      "-----------------------------\n",
      "64000 0.9581268619848197\n",
      "36.30967116355896\n",
      "2248.0806250572205\n",
      "-----------------------------\n",
      "65000 0.9730975942033325\n",
      "37.88284683227539\n",
      "2286.513880968094\n",
      "-----------------------------\n",
      "66000 0.9880683264218453\n",
      "36.47227597236633\n",
      "2323.533613920212\n",
      "-----------------------------\n",
      "66797 1.0\n",
      "30.83023190498352\n",
      "2354.7631878852844\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "log = {}\n",
    "log['securitization'] = term\n",
    "master_list = []\n",
    "broke = 0\n",
    "cautions = 0\n",
    "status = 'good'\n",
    "s1 = time.time()\n",
    "ids_count = 0\n",
    "for ids in id_lists:\n",
    "    \n",
    "    # get update\n",
    "    ids_count = ids_count + len(ids)\n",
    "    percent = ids_count / len(all_ids)\n",
    "    print(ids_count, percent)\n",
    "    \n",
    "    # create sub\n",
    "    sub_df = data[data[id_col].isin(ids)]\n",
    "    sub_df['indexTransaction'] = sub_df.index\n",
    "    sub_df = sub_df.reset_index(drop = True)\n",
    "    splits = list(sub_df.groupby(id_col)) \n",
    "    l = [splits[n_][1] for n_ in list(range(len(splits)))]\n",
    "    a = np.array(l)\n",
    "    \n",
    "    # get results\n",
    "    s2 = time.time()\n",
    "    try:\n",
    "        exception_status = False\n",
    "        results = [convert_static(d, exception_status) for d in a]\n",
    "        for r in results:\n",
    "            master_list.append(r)\n",
    "    except:\n",
    "        try:\n",
    "            exception_status = True \n",
    "            cautions = cautions + 1\n",
    "            print('HITTING EXCEPTION')\n",
    "            for l2 in l:\n",
    "                res = convert_static(l2, exception_status)\n",
    "                master_list.append(res)\n",
    "        except:\n",
    "            status = 'bad'\n",
    "            broke = broke + 1\n",
    "            if broke > 0:\n",
    "                sys.exit('Too many errors...')\n",
    "    \n",
    "    e1 = time.time()\n",
    "    e2 = time.time()\n",
    "    log['{}'.format(ids_count)] = (e2 - s2)\n",
    "    \n",
    "    print(e2 - s2)\n",
    "    print(e1 - s1)\n",
    "    print('-----------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "log['total_time'] = e1 - s1\n",
    "log['run_status'] = status\n",
    "log['cautions'] = cautions\n",
    "log['duplicate_rows'] = dup_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.DataFrame(master_list)\n",
    "log['loans'] = len(master)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = master['obligorCreditScoreLocCurrent'].mean()\n",
    "if cs <= 620:\n",
    "    rating = 'sub_prime'\n",
    "elif cs > 620 and cs <= 720:\n",
    "    rating = 'near_prime'\n",
    "elif cs > 720:\n",
    "    rating = 'prime'\n",
    "else:\n",
    "    rating = 'other'\n",
    "log['average_credit'] = cs\n",
    "log['rating'] = rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_ids) == len(master_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prepaid or Matured         32463\n",
       "NaN                        15809\n",
       "Charged-off                15353\n",
       "Repurchased or Replaced    3172 \n",
       "Name: accountStatusEvent, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master['accountStatusEvent'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding final fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['securitization'] = term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(row):\n",
    "    \n",
    "    \"\"\"\n",
    "    Set target var\n",
    "    \"\"\"\n",
    "    \n",
    "    init = str(row['accountStatusEvent'])\n",
    "    remaining = row['remainingTermToMaturityNumberMinPrior']\n",
    "    #remaining = row['remainingTermToMaturityNumberLocCurrent']\n",
    "    #remaining = row['remainingTermToMaturityNumberLocPrior']\n",
    "    \n",
    "    if init == 'Charged-off':\n",
    "        res = 'Charged-off'\n",
    "        return res\n",
    "    elif init == 'Prepaid or Matured' and remaining > 1:\n",
    "        res = 'Prepaid'\n",
    "        return res\n",
    "    elif init == 'Prepaid or Matured' and remaining < 2:\n",
    "        res = 'Closed'\n",
    "        return res\n",
    "    elif init == 'nan':\n",
    "        res = 'Active or other'\n",
    "        return res\n",
    "    else:\n",
    "        res = 'Active or other'\n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['target'] = master.apply(get_target, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prepaid            31614\n",
       "Active or other    18981\n",
       "Charged-off        15353\n",
       "Closed             849  \n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master['target'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_regions(state):\n",
    "    \n",
    "    \"\"\"\n",
    "    Get region\n",
    "    \"\"\"\n",
    "    \n",
    "    if state in west:\n",
    "        return 'West'\n",
    "    elif state in south_west:\n",
    "        return 'SouthWest'\n",
    "    elif state in south_east:\n",
    "        return 'SouthEast'\n",
    "    elif state in mid_west:\n",
    "        return 'MidWest'\n",
    "    elif state in north_east:\n",
    "        return 'NorthEast'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['region'] = np.nan\n",
    "    \n",
    "master['region'] = master['obligorGeographicLocationLocCurrent'].apply(finding_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_year(init):\n",
    "    \n",
    "    \"\"\"\n",
    "    Get origination year\n",
    "    \"\"\"\n",
    "    \n",
    "    year = init[0:4]\n",
    "    \n",
    "    return year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_col = 'originationDateRLocCurrent'\n",
    "\n",
    "year_vals = master[year_col].values\n",
    "years = [get_or_year(y) for y in year_vals]\n",
    "master['originationYear'] = years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['originationDate'] = pd.to_datetime(master['originationDateRLocCurrent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66797, 713)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#master[master['exceptionStatus'].isin([True])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding outcome for transaction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_col = 'id'\n",
    "m_type = 'left'\n",
    "merged = pd.merge(data, master[[m_col, 'target']], on = m_col, how = m_type)\n",
    "ft_shape = merged.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2178828"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bool = init_shape == sec_shape == ft_shape\n",
    "log['lengths_match'] = final_bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vals cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_cols = [col for col in list(master.columns) if 'vals' in col.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_vals(row, column):\n",
    "\n",
    "    \"\"\"\n",
    "    Fix column values\n",
    "    \"\"\"\n",
    "\n",
    "    init = str(row[column])\n",
    "\n",
    "    ret_val = 'str: ' + init\n",
    "\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obligorIncomeVerificationLevelCodeValsCurrent\n",
      "interestCalculationTypeCodeValsCurrent\n",
      "zeroBalanceCodeValsCurrent\n",
      "subventedValsCurrent\n",
      "modificationTypeCodeValsCurrent\n",
      "assetSubjectDemandStatusCodeValsCurrent\n",
      "repurchaseReplacementReasonCodeValsCurrent\n",
      "vehicleValueSourceCodeValsCurrent\n",
      "accountStatusValsCurrent\n",
      "obligorEmploymentVerificationCodeValsCurrent\n",
      "originalInterestRateTypeCodeValsCurrent\n",
      "vehicleNewUsedCodeValsCurrent\n",
      "vehicleTypeCodeValsCurrent\n",
      "paymentTypeCodeValsCurrent\n",
      "indexAccountValsCurrent\n",
      "servicingAdvanceMethodCodeValsCurrent\n",
      "indexTransactionValsCurrent\n",
      "zeroBalanceCodeMValsCurrent\n",
      "obligorIncomeVerificationLevelCodeValsPrior\n",
      "interestCalculationTypeCodeValsPrior\n",
      "zeroBalanceCodeValsPrior\n",
      "subventedValsPrior\n",
      "modificationTypeCodeValsPrior\n",
      "assetSubjectDemandStatusCodeValsPrior\n",
      "repurchaseReplacementReasonCodeValsPrior\n",
      "vehicleValueSourceCodeValsPrior\n",
      "accountStatusValsPrior\n",
      "obligorEmploymentVerificationCodeValsPrior\n",
      "originalInterestRateTypeCodeValsPrior\n",
      "vehicleNewUsedCodeValsPrior\n",
      "vehicleTypeCodeValsPrior\n",
      "paymentTypeCodeValsPrior\n",
      "indexAccountValsPrior\n",
      "servicingAdvanceMethodCodeValsPrior\n",
      "indexTransactionValsPrior\n",
      "zeroBalanceCodeMValsPrior\n",
      "obligorIncomeVerificationLevelCodeValsRandom\n",
      "interestCalculationTypeCodeValsRandom\n",
      "zeroBalanceCodeValsRandom\n",
      "subventedValsRandom\n",
      "modificationTypeCodeValsRandom\n",
      "assetSubjectDemandStatusCodeValsRandom\n",
      "repurchaseReplacementReasonCodeValsRandom\n",
      "vehicleValueSourceCodeValsRandom\n",
      "accountStatusValsRandom\n",
      "obligorEmploymentVerificationCodeValsRandom\n",
      "originalInterestRateTypeCodeValsRandom\n",
      "vehicleNewUsedCodeValsRandom\n",
      "vehicleTypeCodeValsRandom\n",
      "paymentTypeCodeValsRandom\n",
      "indexAccountValsRandom\n",
      "servicingAdvanceMethodCodeValsRandom\n",
      "indexTransactionValsRandom\n",
      "zeroBalanceCodeMValsRandom\n"
     ]
    }
   ],
   "source": [
    "for col in vals_cols:\n",
    "    print(col)\n",
    "    master[col] = master[col].astype(str)\n",
    "    master[col] = 'str: ' + master[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/karus_datasets/Santander/Santander 2017-1/'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_folder = 'data/karus_datasets/{}/{} {}/'.format(originator, originator, add_id)\n",
    "export_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(export_folder)\n",
    "    print('created {}'.format(export_folder))\n",
    "except:\n",
    "    print('folder already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/karus_datasets/Santander/Santander 2017-1/static.csv\n",
      "(66797, 713)\n"
     ]
    }
   ],
   "source": [
    "#e_folder = 'data/static/'\n",
    "e_file = 'static.csv'.format(add_id)\n",
    "e_path = export_folder + e_file\n",
    "print(e_path)\n",
    "print(master.shape)\n",
    "master.to_csv(e_path, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/karus_datasets/Santander/Santander 2017-1/transaction.csv\n",
      "(2178828, 99)\n"
     ]
    }
   ],
   "source": [
    "#t_folder = 'data/transaction/prepared/'\n",
    "t_file = 'transaction.csv'.format(add_id)\n",
    "t_path = export_folder + t_file\n",
    "print(t_path)\n",
    "print(merged.shape)\n",
    "merged.to_csv(t_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export log\n",
    "#j_folder = 'data/static/log/'\n",
    "j_file = '{} log.json'.format(term)\n",
    "j_path = export_folder + j_file\n",
    "with open(j_path, 'w') as outfile:  \n",
    "    json.dump(log, outfile, indent = 4, separators = (',', ': '), sort_keys = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue...\n"
     ]
    }
   ],
   "source": [
    "print('continue...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
