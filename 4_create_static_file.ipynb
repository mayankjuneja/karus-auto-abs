{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 12 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from pandarallel import pandarallel\n",
    "import re\n",
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "import os\n",
    "from project_functions import get_originator\n",
    "\n",
    "pandarallel.initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/kn/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "n = 750\n",
    "pd.set_option('display.max_columns', n)\n",
    "pd.set_option('display.max_rows', n)\n",
    "pd.set_option('display.max_colwidth', -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = 'Santander Drive Auto Receivables Trust 2020-4 Data Tape'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Santander\n",
      "2020-4\n"
     ]
    }
   ],
   "source": [
    "originator = get_originator(term)[0]\n",
    "finder = re.compile(r'\\b\\d{4}-[A-Za-z\\d]+\\b')\n",
    "init_id = re.search(finder, term)\n",
    "add_id = init_id.group()\n",
    "print(originator)\n",
    "print(add_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366189, 73)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load abs\n",
    "folder = 'data/karus_datasets/{}/{} {}/'.format(originator, originator, add_id)\n",
    "file = 'transaction_raw.csv'.format(term)\n",
    "path = folder + file\n",
    "data = pd.read_csv(path)\n",
    "init_shape = data.shape[0]\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fields\n",
    "f_folder = 'data/json/fields/'\n",
    "f_file = 'fields.json'\n",
    "f_path = f_folder + f_file\n",
    "with open(f_path) as f:\n",
    "    fields = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mapper\n",
    "m_folder = 'data/dictionary/mapper/'\n",
    "m_file = 'mapper.json'\n",
    "m_path = m_folder + m_file\n",
    "with open(m_path) as f:\n",
    "    mapper = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_id = fields['init_id'][0]\n",
    "date_cols = fields['dates']\n",
    "replacer_cols = fields['replace_dash']\n",
    "clean_cols = fields['clean']\n",
    "m_cols = fields['map']\n",
    "event_cols = fields['event']\n",
    "loc_cols = fields['all_loc']\n",
    "numeric_cols = fields['numeric']\n",
    "all_vals_cols = fields['all_vals']\n",
    "min_max_cols = fields['min_max']\n",
    "west = fields['regions']['west']\n",
    "south_west = fields['regions']['south_west']\n",
    "south_east = fields['regions']['south_east']\n",
    "mid_west = fields['regions']['mid_west']\n",
    "north_east = fields['regions']['north_east']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID and dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_date(init):\n",
    "    \n",
    "    \"\"\"\n",
    "    Reorder date\n",
    "    \"\"\"\n",
    "    \n",
    "    init = str(init)\n",
    "    if init != '-':\n",
    "        if '/' not in init:\n",
    "            y = init[6:10]\n",
    "            m = init[0:2]\n",
    "            d = init[3:5]\n",
    "            date = y + '-' + m + '-' + d\n",
    "        elif '/' in init:\n",
    "            y = init[3:7]\n",
    "            m = init[0:2]\n",
    "            date = y + '-' + m\n",
    "    else:\n",
    "        date = ''\n",
    "    \n",
    "    return date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['id'] = data[init_id].str.replace('=', '').str.replace('\"', '').str.strip() + '-' + add_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reportingPeriodBeginningDate\n",
      "DemandResolutionDate\n",
      "reportingPeriodEndingDate\n",
      "loanMaturityDate\n",
      "originationDate\n",
      "interestPaidThroughDate\n",
      "originalFirstPaymentDate\n",
      "mostRecentServicingTransferReceivedDate\n",
      "zeroBalanceEffectiveDate\n"
     ]
    }
   ],
   "source": [
    "for col in date_cols:\n",
    "    print(col)\n",
    "    values = data[col].values\n",
    "    dates = [reorder_date(v) for v in values]\n",
    "    data['{}R'.format(col)] = dates\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(302642, 83)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sort_values(by=['reportingPeriodBeginningDateR'], ascending=False)\n",
    "data = data.drop_duplicates(subset = ['id', 'reportingPeriodBeginningDateR'], keep = 'first')\n",
    "sec_shape = data.shape[0]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows\n"
     ]
    }
   ],
   "source": [
    "if init_shape == sec_shape:\n",
    "    dup_rows = False\n",
    "    print('Matching shapes')\n",
    "else:\n",
    "    dup_rows = True \n",
    "    print('Duplicate rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_col = 'loanMaturityDate'\n",
    "# t_col = '{}R'.format(s_col)\n",
    "# data[[s_col, t_col]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[replacer_cols] = data[replacer_cols].replace('-', np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean cols\n",
    "for col in clean_cols:\n",
    "    data[col] = data[col].astype(str)\n",
    "    data[col] = data[col].str.strip()\n",
    "    data[col] = data[col].astype(float)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_val(init, column):\n",
    "    \n",
    "    \"\"\"\n",
    "    Replace numeric values\n",
    "    \"\"\"\n",
    "    \n",
    "    init = str(init).strip().replace(';', '')\n",
    "    if init in ['0', '1', '2', '3', '4', '5', '98', '99']:\n",
    "        mapped = mapper[column][init]\n",
    "        return mapped\n",
    "    else:\n",
    "        if init[0] in ['0', '1', '2', '3', '4', '5']:\n",
    "            use = init[0]\n",
    "        elif init == '-':\n",
    "            use_keys = list(mapper[column].keys())\n",
    "            if '98' in use_keys:\n",
    "                use = '98'\n",
    "            elif '99' in use_keys:\n",
    "                use = '99'\n",
    "        else:\n",
    "            use = init\n",
    "        mapped = mapper[column][use]\n",
    "        \n",
    "    return mapped\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obligorIncomeVerificationLevelCode\n",
      "interestCalculationTypeCode\n",
      "zeroBalanceCode\n",
      "modificationTypeCode\n",
      "assetSubjectDemandStatusCode\n",
      "repurchaseReplacementReasonCode\n",
      "vehicleValueSourceCode\n",
      "obligorEmploymentVerificationCode\n",
      "vehicleNewUsedCode\n",
      "vehicleTypeCode\n",
      "paymentTypeCode\n",
      "servicingAdvanceMethodCode\n",
      "originalInterestRateTypeCode\n",
      "subvented\n"
     ]
    }
   ],
   "source": [
    "for col in m_cols:\n",
    "    print(col)\n",
    "    values = data[col].values\n",
    "    ret_vals = [replace_val(v, col) for v in values]\n",
    "    data['{}M'.format(col)] = ret_vals\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_col = 'subvented'\n",
    "# t_col = '{}M'.format(s_col)\n",
    "# data[[s_col, t_col]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Account status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acct_status(row, b_col, e_col, zero_col, thresh):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create karus account status\n",
    "    \"\"\"\n",
    "    \n",
    "    b = float(row[b_col])\n",
    "    e = float(row[e_col])\n",
    "    z = str(row[zero_col])\n",
    "    \n",
    "    if z in ['Charged-off', 'Repurchased or Replaced']:\n",
    "        res = z\n",
    "        return res\n",
    "    if b < thresh and e < thresh:\n",
    "        res = 'Prepaid or Matured'\n",
    "        return res\n",
    "    if z in ['Unavailable', 'Prepaid or Matured']:\n",
    "        res = z\n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_col = 'reportingPeriodBeginningLoanBalanceAmount'\n",
    "e_col = 'nextReportingPeriodPaymentAmountDue'\n",
    "z_col = 'zeroBalanceCodeM'\n",
    "thresh = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['accountStatus'] = data.parallel_apply(acct_status, args = (b_col, e_col, z_col, thresh, ), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unavailable                300268\n",
       "Prepaid or Matured         2249  \n",
       "Repurchased or Replaced    88    \n",
       "Charged-off                37    \n",
       "Name: accountStatus, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['accountStatus'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currentDelinquencyStatus\n",
      "paymentToIncomePercentage\n",
      "paymentExtendedNumber\n",
      "otherAssessedUncollectedServicerFeeAmount\n",
      "totalActualAmountPaid\n",
      "actualInterestCollectedAmount\n",
      "remainingTermToMaturityNumber\n",
      "reportingPeriodScheduledPaymentAmount\n",
      "vehicleValueAmount\n",
      "reportingPeriodInterestRatePercentage\n",
      "scheduledInterestAmount\n",
      "actualPrincipalCollectedAmount\n",
      "actualOtherCollectedAmount\n",
      "reportingPeriodActualEndBalanceAmount\n",
      "servicingFlatFeeAmount\n",
      "chargedoffPrincipalAmount\n",
      "servicingFeePercentage\n",
      "otherPrincipalAdjustmentAmount\n",
      "obligorCreditScore\n",
      "originalInterestRatePercentage\n",
      "nextReportingPeriodPaymentAmountDue\n",
      "gracePeriodNumber\n",
      "originalLoanTerm\n",
      "repurchaseAmount\n",
      "recoveredAmount\n",
      "servicerAdvancedAmount\n",
      "originalLoanAmount\n",
      "repossessedProceedsAmount\n",
      "nextInterestRatePercentage\n",
      "scheduledPrincipalAmount\n",
      "reportingPeriodBeginningLoanBalanceAmount\n"
     ]
    }
   ],
   "source": [
    "# force convert cols to numeric\n",
    "for col in numeric_cols:\n",
    "    print(col)\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = 'id'\n",
    "status_col = 'accountStatus'\n",
    "values = ['Charged-off', 'Prepaid or Matured', 'Repurchased or Replaced']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76183"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = list(data[id_col].unique())\n",
    "#all_ids = all_ids[:1000]\n",
    "print_vals = list(range(0, len(all_ids), 100))\n",
    "len(all_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break ids into list chunks\n",
    "num = 1000\n",
    "id_lists = [all_ids[i:i + num] for i in range(0, len(all_ids), num)]  \n",
    "#id_lists = [id_lists[-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_static(df, exception_status):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create static df\n",
    "    \"\"\"\n",
    "    \n",
    "    #df = init.reset_values(drop = True)\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    df = df.sort_values('reportingPeriodBeginningDateR', ascending = False)\n",
    "    df['indexAccount'] = df.index\n",
    "    _id = df[id_col].iloc[0]\n",
    "\n",
    "    # dict\n",
    "    account_dict = {}\n",
    "    account_dict['exceptionStatus'] = exception_status\n",
    "    account_dict[id_col] = _id\n",
    "    account_dict['records'] = len(df)\n",
    "\n",
    "    # current status of loan\n",
    "    for col in loc_cols:\n",
    "        account_dict['{}LocCurrent'.format(col)] = df[col].iloc[0]\n",
    "    for col in min_max_cols:\n",
    "        account_dict['{}MaxCurrent'.format(col)] = df[col].max()\n",
    "        account_dict['{}MinCurrent'.format(col)] = df[col].min()\n",
    "    for col in all_vals_cols:\n",
    "        vals = list(df[col].unique())\n",
    "        use_vals = ' | '.join(str(val) for val in vals)\n",
    "        account_dict['{}ValsCurrent'.format(col)] = use_vals\n",
    "    for col in numeric_cols:\n",
    "        _sum = df[col].sum()\n",
    "        account_dict['{}SumCurrent'.format(col)] = _sum\n",
    "        vec = list(df[col])\n",
    "        vec = [v for v in vec if str(v) != 'nan']\n",
    "        if len(vec) > 0:\n",
    "            _len = len(vec)\n",
    "            weights = sorted([1 + i for i in list(range(_len))], reverse=True)\n",
    "            wa = np.average(vec, weights=weights)\n",
    "            account_dict['{}WeightedCurrent'.format(col)] = wa\n",
    "        else:\n",
    "            account_dict['{}WeightedCurrent'.format(col)] = 0\n",
    "\n",
    "    # event information\n",
    "    init_vals = list(df[status_col].unique())\n",
    "    inter = list(set(values).intersection(init_vals))\n",
    "    if len(inter) > 0:\n",
    "        account_dict['eventOccurred'] = 1\n",
    "        n = df[status_col].where(df[status_col].isin(values)).last_valid_index()\n",
    "        account_dict['eventIndex'] = n\n",
    "        n_bool = True\n",
    "        single = df.loc[[n]]\n",
    "        for col in event_cols:\n",
    "            account_dict['{}Event'.format(col)] = single[col].iloc[0]\n",
    "\n",
    "        # prior to event\n",
    "        init = n+1\n",
    "        sub = df[init:len(df)]\n",
    "        sub.reset_index(drop = True, inplace = True)\n",
    "        account_dict['priorHistory'] = len(sub)\n",
    "        sub_bool = True\n",
    "        if len(sub) > 0:\n",
    "            for col in loc_cols:\n",
    "                account_dict['{}LocPrior'.format(col)] = sub[col].iloc[0]\n",
    "            for col in min_max_cols:\n",
    "                account_dict['{}MinPrior'.format(col)] = sub[col].min()\n",
    "                account_dict['{}MaxPrior'.format(col)] = sub[col].max()\n",
    "            for col in all_vals_cols:\n",
    "                vals = list(sub[col].unique())\n",
    "                use_vals = ' | '.join(str(val) for val in vals)\n",
    "                account_dict['{}ValsPrior'.format(col)] = use_vals\n",
    "            for col in numeric_cols:\n",
    "                account_dict['{}SumPrior'.format(col)] = sub[col].sum()\n",
    "                vec = list(sub[col])\n",
    "                vec = [v for v in vec if str(v) != 'nan']\n",
    "                if len(vec) > 0:\n",
    "                    _len = len(vec)\n",
    "                    weights = sorted([1 + i for i in list(range(_len))], reverse=True)\n",
    "                    wa = np.average(vec, weights=weights)\n",
    "                    account_dict['{}WeightedPrior'.format(col)] = wa\n",
    "                else:\n",
    "                    account_dict['{}WeightedPrior'.format(col)] = 0\n",
    "\n",
    "            # random\n",
    "            len_sub = len(sub)            \n",
    "            s = random.randint(0, len_sub)\n",
    "            if s == len_sub:\n",
    "                s = s -1\n",
    "            r_sub = sub[s:len_sub].reset_index(drop = True)\n",
    "            account_dict['randomIndex'] = s\n",
    "            for col in loc_cols:\n",
    "                account_dict['{}LocRandom'.format(col)] = r_sub[col].iloc[0]\n",
    "            for col in min_max_cols:\n",
    "                account_dict['{}MinRandom'.format(col)] = r_sub[col].min()\n",
    "                account_dict['{}MaxRandom'.format(col)] = r_sub[col].max()\n",
    "            for col in all_vals_cols:\n",
    "                vals = list(r_sub[col].unique())\n",
    "                use_vals = ' | '.join(str(val) for val in vals)\n",
    "                account_dict['{}ValsRandom'.format(col)] = use_vals\n",
    "            for col in numeric_cols:\n",
    "                account_dict['{}SumRandom'.format(col)] = r_sub[col].sum()\n",
    "                vec = list(r_sub[col])\n",
    "                vec = [v for v in vec if str(v) != 'nan']\n",
    "                if len(vec) > 0:\n",
    "                    _len = len(vec)\n",
    "                    weights = sorted([1 + i for i in list(range(_len))], reverse=True)\n",
    "                    wa = np.average(vec, weights=weights)\n",
    "                    account_dict['{}WeightedRandom'.format(col)] = wa\n",
    "                else:\n",
    "                    account_dict['{}WeightedRandom'.format(col)] = 0\n",
    "\n",
    "        # if event is first row of sub       \n",
    "        else:\n",
    "            for col in loc_cols:\n",
    "                account_dict['{}LocPrior'.format(col)] = df[col].iloc[0]\n",
    "            for col in min_max_cols:\n",
    "                account_dict['{}MinPrior'.format(col)] = df[col].min()\n",
    "                account_dict['{}MaxPrior'.format(col)] = df[col].max()\n",
    "            for col in all_vals_cols:\n",
    "                vals = list(df[col].unique())\n",
    "                use_vals = ' | '.join(str(val) for val in vals)\n",
    "                account_dict['{}ValsPrior'.format(col)] = use_vals\n",
    "            for col in numeric_cols:\n",
    "                account_dict['{}SumPrior'.format(col)] = df[col].sum()\n",
    "                account_dict['{}WeightedPrior'.format(col)] = df[col].iloc[0]\n",
    "\n",
    "    # if no event        \n",
    "    else:\n",
    "        account_dict['eventOccurred'] = 0\n",
    "        account_dict['priorHistory'] = len(df)\n",
    "        sub_bool = False\n",
    "        n_bool = False\n",
    "        for col in event_cols:\n",
    "            account_dict['{}Event'.format(col)] = np.nan\n",
    "        for col in loc_cols:\n",
    "            account_dict['{}LocPrior'.format(col)] = np.nan\n",
    "        for col in min_max_cols:\n",
    "            account_dict['{}MinPrior'.format(col)] = np.nan\n",
    "            account_dict['{}MaxPrior'.format(col)] = np.nan\n",
    "        for col in all_vals_cols:\n",
    "            account_dict['{}ValsPrior'.format(col)] = np.nan\n",
    "        for col in numeric_cols:\n",
    "            account_dict['{}SumPrior'.format(col)] = np.nan\n",
    "            account_dict['{}WeightedPrior'.format(col)] = np.nan\n",
    "\n",
    "        # random set to nan\n",
    "        account_dict['randomIndex'] = np.nan\n",
    "        for col in loc_cols:\n",
    "            account_dict['{}LocRandom'.format(col)] = np.nan\n",
    "        for col in min_max_cols:\n",
    "            account_dict['{}MinRandom'.format(col)] = np.nan\n",
    "            account_dict['{}MaxRandom'.format(col)] = np.nan\n",
    "        for col in all_vals_cols:\n",
    "            account_dict['{}ValsRandom'.format(col)] = np.nan\n",
    "        for col in numeric_cols:\n",
    "            account_dict['{}SumRandom'.format(col)] = np.nan\n",
    "            account_dict['{}WeightedRandom'.format(col)] = np.nan\n",
    "\n",
    "    return account_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.01312628801701167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/kn/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITTING EXCEPTION\n",
      "13.012834072113037\n",
      "13.897285223007202\n",
      "-----------------------------\n",
      "2000 0.02625257603402334\n",
      "HITTING EXCEPTION\n",
      "15.878430843353271\n",
      "30.355759143829346\n",
      "-----------------------------\n",
      "3000 0.03937886405103501\n",
      "HITTING EXCEPTION\n",
      "16.958887100219727\n",
      "47.86919116973877\n",
      "-----------------------------\n",
      "4000 0.05250515206804668\n",
      "HITTING EXCEPTION\n",
      "16.801839113235474\n",
      "65.21172714233398\n",
      "-----------------------------\n",
      "5000 0.06563144008505835\n",
      "HITTING EXCEPTION\n",
      "16.48452115058899\n",
      "82.30040216445923\n",
      "-----------------------------\n",
      "6000 0.07875772810207002\n",
      "HITTING EXCEPTION\n",
      "17.903417825698853\n",
      "100.73804593086243\n",
      "-----------------------------\n",
      "7000 0.09188401611908169\n",
      "HITTING EXCEPTION\n",
      "14.778585195541382\n",
      "116.05221033096313\n",
      "-----------------------------\n",
      "8000 0.10501030413609336\n",
      "HITTING EXCEPTION\n",
      "12.713546991348267\n",
      "129.2815752029419\n",
      "-----------------------------\n",
      "9000 0.11813659215310503\n",
      "HITTING EXCEPTION\n",
      "13.555706024169922\n",
      "143.3389081954956\n",
      "-----------------------------\n",
      "10000 0.1312628801701167\n",
      "HITTING EXCEPTION\n",
      "12.925817966461182\n",
      "156.70274209976196\n",
      "-----------------------------\n",
      "11000 0.14438916818712835\n",
      "HITTING EXCEPTION\n",
      "13.790511846542358\n",
      "171.0370991230011\n",
      "-----------------------------\n",
      "12000 0.15751545620414004\n",
      "HITTING EXCEPTION\n",
      "13.74500298500061\n",
      "185.26443600654602\n",
      "-----------------------------\n",
      "13000 0.1706417442211517\n",
      "HITTING EXCEPTION\n",
      "14.144960641860962\n",
      "199.93701195716858\n",
      "-----------------------------\n",
      "14000 0.18376803223816338\n",
      "HITTING EXCEPTION\n",
      "14.960373878479004\n",
      "215.36495113372803\n",
      "-----------------------------\n",
      "15000 0.19689432025517503\n",
      "HITTING EXCEPTION\n",
      "14.8668372631073\n",
      "230.82806134223938\n",
      "-----------------------------\n",
      "16000 0.21002060827218672\n",
      "HITTING EXCEPTION\n",
      "14.494584083557129\n",
      "245.84171414375305\n",
      "-----------------------------\n",
      "17000 0.22314689628919837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/kn/lib/python3.7/site-packages/ipykernel_launcher.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.861611127853394\n",
      "262.10926628112793\n",
      "-----------------------------\n",
      "18000 0.23627318430621005\n",
      "HITTING EXCEPTION\n",
      "15.784909963607788\n",
      "278.4834680557251\n",
      "-----------------------------\n",
      "19000 0.2493994723232217\n",
      "18.703212022781372\n",
      "297.6762070655823\n",
      "-----------------------------\n",
      "20000 0.2625257603402334\n",
      "HITTING EXCEPTION\n",
      "14.412221193313599\n",
      "312.6927533149719\n",
      "-----------------------------\n",
      "21000 0.27565204835724505\n",
      "HITTING EXCEPTION\n",
      "13.343019008636475\n",
      "326.4953660964966\n",
      "-----------------------------\n",
      "22000 0.2887783363742567\n",
      "14.289819717407227\n",
      "341.2162890434265\n",
      "-----------------------------\n",
      "23000 0.3019046243912684\n",
      "HITTING EXCEPTION\n",
      "13.837914228439331\n",
      "355.55017924308777\n",
      "-----------------------------\n",
      "24000 0.3150309124082801\n",
      "HITTING EXCEPTION\n",
      "13.53745985031128\n",
      "369.5529580116272\n",
      "-----------------------------\n",
      "25000 0.32815720042529173\n",
      "HITTING EXCEPTION\n",
      "13.701888084411621\n",
      "383.7839901447296\n",
      "-----------------------------\n",
      "26000 0.3412834884423034\n",
      "HITTING EXCEPTION\n",
      "14.589529037475586\n",
      "398.83017015457153\n",
      "-----------------------------\n",
      "27000 0.3544097764593151\n",
      "HITTING EXCEPTION\n",
      "15.503095149993896\n",
      "414.90255308151245\n",
      "-----------------------------\n",
      "28000 0.36753606447632675\n",
      "HITTING EXCEPTION\n",
      "14.15337586402893\n",
      "429.5277690887451\n",
      "-----------------------------\n",
      "29000 0.3806623524933384\n",
      "HITTING EXCEPTION\n",
      "14.17794919013977\n",
      "444.1280801296234\n",
      "-----------------------------\n",
      "30000 0.39378864051035006\n",
      "HITTING EXCEPTION\n",
      "13.129433631896973\n",
      "457.7240629196167\n",
      "-----------------------------\n",
      "31000 0.4069149285273618\n",
      "HITTING EXCEPTION\n",
      "13.341753959655762\n",
      "471.5747940540314\n",
      "-----------------------------\n",
      "32000 0.42004121654437343\n",
      "HITTING EXCEPTION\n",
      "13.374381065368652\n",
      "485.46102118492126\n",
      "-----------------------------\n",
      "33000 0.4331675045613851\n",
      "HITTING EXCEPTION\n",
      "13.95041036605835\n",
      "499.8857033252716\n",
      "-----------------------------\n",
      "34000 0.44629379257839674\n",
      "HITTING EXCEPTION\n",
      "13.920536041259766\n",
      "514.2785351276398\n",
      "-----------------------------\n",
      "35000 0.4594200805954084\n",
      "HITTING EXCEPTION\n",
      "13.509454011917114\n",
      "528.3572211265564\n",
      "-----------------------------\n",
      "36000 0.4725463686124201\n",
      "HITTING EXCEPTION\n",
      "12.286539077758789\n",
      "541.0728890895844\n",
      "-----------------------------\n",
      "37000 0.48567265662943176\n",
      "HITTING EXCEPTION\n",
      "11.838845014572144\n",
      "553.3304750919342\n",
      "-----------------------------\n",
      "38000 0.4987989446464434\n",
      "HITTING EXCEPTION\n",
      "11.816924810409546\n",
      "565.6185500621796\n",
      "-----------------------------\n",
      "39000 0.5119252326634551\n",
      "HITTING EXCEPTION\n",
      "12.166561841964722\n",
      "578.1837229728699\n",
      "-----------------------------\n",
      "40000 0.5250515206804668\n",
      "HITTING EXCEPTION\n",
      "12.717801809310913\n",
      "591.3990750312805\n",
      "-----------------------------\n",
      "41000 0.5381778086974784\n",
      "HITTING EXCEPTION\n",
      "11.722927808761597\n",
      "603.5856211185455\n",
      "-----------------------------\n",
      "42000 0.5513040967144901\n",
      "HITTING EXCEPTION\n",
      "13.036677837371826\n",
      "617.0277202129364\n",
      "-----------------------------\n",
      "43000 0.5644303847315018\n",
      "HITTING EXCEPTION\n",
      "12.76075792312622\n",
      "630.2026660442352\n",
      "-----------------------------\n",
      "44000 0.5775566727485134\n",
      "HITTING EXCEPTION\n",
      "15.69971513748169\n",
      "646.3772521018982\n",
      "-----------------------------\n",
      "45000 0.5906829607655251\n",
      "HITTING EXCEPTION\n",
      "15.830655813217163\n",
      "662.8010449409485\n",
      "-----------------------------\n",
      "46000 0.6038092487825368\n",
      "HITTING EXCEPTION\n",
      "16.00573992729187\n",
      "679.3834931850433\n",
      "-----------------------------\n",
      "47000 0.6169355367995485\n",
      "HITTING EXCEPTION\n",
      "15.9253671169281\n",
      "695.8392813205719\n",
      "-----------------------------\n",
      "48000 0.6300618248165601\n",
      "HITTING EXCEPTION\n",
      "17.11160182952881\n",
      "713.4914870262146\n",
      "-----------------------------\n",
      "49000 0.6431881128335718\n",
      "HITTING EXCEPTION\n",
      "18.646174907684326\n",
      "732.6856782436371\n",
      "-----------------------------\n",
      "50000 0.6563144008505835\n",
      "HITTING EXCEPTION\n",
      "19.09577703475952\n",
      "752.36079621315\n",
      "-----------------------------\n",
      "51000 0.6694406888675951\n",
      "18.4578959941864\n",
      "771.3278431892395\n",
      "-----------------------------\n",
      "52000 0.6825669768846068\n",
      "HITTING EXCEPTION\n",
      "15.252415180206299\n",
      "787.2154922485352\n",
      "-----------------------------\n",
      "53000 0.6956932649016184\n",
      "HITTING EXCEPTION\n",
      "13.398262977600098\n",
      "801.0230271816254\n",
      "-----------------------------\n",
      "54000 0.7088195529186302\n",
      "HITTING EXCEPTION\n",
      "13.385251998901367\n",
      "814.9544200897217\n",
      "-----------------------------\n",
      "55000 0.7219458409356418\n",
      "HITTING EXCEPTION\n",
      "13.664078712463379\n",
      "829.1121730804443\n",
      "-----------------------------\n",
      "56000 0.7350721289526535\n",
      "15.917263746261597\n",
      "845.534440279007\n",
      "-----------------------------\n",
      "57000 0.7481984169696652\n",
      "HITTING EXCEPTION\n",
      "16.902243852615356\n",
      "862.9422919750214\n",
      "-----------------------------\n",
      "58000 0.7613247049866768\n",
      "14.569597959518433\n",
      "878.01766705513\n",
      "-----------------------------\n",
      "59000 0.7744509930036885\n",
      "13.52228593826294\n",
      "891.9381101131439\n",
      "-----------------------------\n",
      "60000 0.7875772810207001\n",
      "HITTING EXCEPTION\n",
      "16.77992033958435\n",
      "909.236025094986\n",
      "-----------------------------\n",
      "61000 0.8007035690377118\n",
      "HITTING EXCEPTION\n",
      "13.888556003570557\n",
      "923.7313652038574\n",
      "-----------------------------\n",
      "62000 0.8138298570547235\n",
      "HITTING EXCEPTION\n",
      "12.935711860656738\n",
      "937.1066219806671\n",
      "-----------------------------\n",
      "63000 0.8269561450717352\n",
      "HITTING EXCEPTION\n",
      "12.555099964141846\n",
      "950.1682350635529\n",
      "-----------------------------\n",
      "64000 0.8400824330887469\n",
      "HITTING EXCEPTION\n",
      "13.342289924621582\n",
      "963.940633058548\n",
      "-----------------------------\n",
      "65000 0.8532087211057585\n",
      "HITTING EXCEPTION\n",
      "13.944132089614868\n",
      "978.3048141002655\n",
      "-----------------------------\n",
      "66000 0.8663350091227702\n",
      "HITTING EXCEPTION\n",
      "13.077010869979858\n",
      "991.8749523162842\n",
      "-----------------------------\n",
      "67000 0.8794612971397818\n",
      "HITTING EXCEPTION\n",
      "15.1410071849823\n",
      "1007.572653055191\n",
      "-----------------------------\n",
      "68000 0.8925875851567935\n",
      "HITTING EXCEPTION\n",
      "13.648016929626465\n",
      "1021.6662912368774\n",
      "-----------------------------\n",
      "69000 0.9057138731738051\n",
      "14.66777491569519\n",
      "1036.7883291244507\n",
      "-----------------------------\n",
      "70000 0.9188401611908168\n",
      "HITTING EXCEPTION\n",
      "13.845218896865845\n",
      "1051.0969910621643\n",
      "-----------------------------\n",
      "71000 0.9319664492078286\n",
      "HITTING EXCEPTION\n",
      "14.764712810516357\n",
      "1066.3365960121155\n",
      "-----------------------------\n",
      "72000 0.9450927372248402\n",
      "HITTING EXCEPTION\n",
      "15.739707946777344\n",
      "1082.6696882247925\n",
      "-----------------------------\n",
      "73000 0.9582190252418519\n",
      "HITTING EXCEPTION\n",
      "15.714799880981445\n",
      "1098.8921573162079\n",
      "-----------------------------\n",
      "74000 0.9713453132588635\n",
      "HITTING EXCEPTION\n",
      "13.497779369354248\n",
      "1112.900817155838\n",
      "-----------------------------\n",
      "75000 0.9844716012758752\n",
      "21.061920881271362\n",
      "1134.4552681446075\n",
      "-----------------------------\n",
      "76000 0.9975978892928868\n",
      "42.01275897026062\n",
      "1176.8857190608978\n",
      "-----------------------------\n",
      "76183 1.0\n",
      "HITTING EXCEPTION\n",
      "7.816637277603149\n",
      "1184.8436563014984\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "log = {}\n",
    "log['securitization'] = term\n",
    "master_list = []\n",
    "broke = 0\n",
    "cautions = 0\n",
    "status = 'good'\n",
    "s1 = time.time()\n",
    "ids_count = 0\n",
    "for ids in id_lists:\n",
    "    \n",
    "    # get update\n",
    "    ids_count = ids_count + len(ids)\n",
    "    percent = ids_count / len(all_ids)\n",
    "    print(ids_count, percent)\n",
    "    \n",
    "    # create sub\n",
    "    sub_df = data[data[id_col].isin(ids)]\n",
    "    sub_df['indexTransaction'] = sub_df.index\n",
    "    sub_df = sub_df.reset_index(drop = True)\n",
    "    splits = list(sub_df.groupby(id_col)) \n",
    "    l = [splits[n_][1] for n_ in list(range(len(splits)))]\n",
    "    a = np.array(l)\n",
    "    \n",
    "    # get results\n",
    "    s2 = time.time()\n",
    "    try:\n",
    "        exception_status = False\n",
    "        results = [convert_static(d, exception_status) for d in a]\n",
    "        for r in results:\n",
    "            master_list.append(r)\n",
    "    except:\n",
    "        try:\n",
    "            exception_status = True \n",
    "            cautions = cautions + 1\n",
    "            print('HITTING EXCEPTION')\n",
    "            for l2 in l:\n",
    "                res = convert_static(l2, exception_status)\n",
    "                master_list.append(res)\n",
    "        except:\n",
    "            status = 'bad'\n",
    "            broke = broke + 1\n",
    "            if broke > 0:\n",
    "                sys.exit('Too many errors...')\n",
    "    \n",
    "    e1 = time.time()\n",
    "    e2 = time.time()\n",
    "    log['{}'.format(ids_count)] = (e2 - s2)\n",
    "    \n",
    "    print(e2 - s2)\n",
    "    print(e1 - s1)\n",
    "    print('-----------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "log['total_time'] = e1 - s1\n",
    "log['run_status'] = status\n",
    "log['cautions'] = cautions\n",
    "log['duplicate_rows'] = dup_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.DataFrame(master_list)\n",
    "log['loans'] = len(master)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = master['obligorCreditScoreLocCurrent'].mean()\n",
    "if cs <= 620:\n",
    "    rating = 'sub_prime'\n",
    "elif cs > 620 and cs <= 720:\n",
    "    rating = 'near_prime'\n",
    "elif cs > 720:\n",
    "    rating = 'prime'\n",
    "else:\n",
    "    rating = 'other'\n",
    "log['average_credit'] = cs\n",
    "log['rating'] = rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_ids) == len(master_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                        73836\n",
       "Prepaid or Matured         2232 \n",
       "Repurchased or Replaced    80   \n",
       "Charged-off                35   \n",
       "Name: accountStatusEvent, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master['accountStatusEvent'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding final fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['securitization'] = term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(row):\n",
    "    \n",
    "    \"\"\"\n",
    "    Set target var\n",
    "    \"\"\"\n",
    "    \n",
    "    init = str(row['accountStatusEvent'])\n",
    "    remaining = row['remainingTermToMaturityNumberMinPrior']\n",
    "    #remaining = row['remainingTermToMaturityNumberLocCurrent']\n",
    "    #remaining = row['remainingTermToMaturityNumberLocPrior']\n",
    "    \n",
    "    if init == 'Charged-off':\n",
    "        res = 'Charged-off'\n",
    "        return res\n",
    "    elif init == 'Prepaid or Matured' and remaining > 1:\n",
    "        res = 'Prepaid'\n",
    "        return res\n",
    "    elif init == 'Prepaid or Matured' and remaining < 2:\n",
    "        res = 'Closed'\n",
    "        return res\n",
    "    elif init == 'nan':\n",
    "        res = 'Active or other'\n",
    "        return res\n",
    "    else:\n",
    "        res = 'Active or other'\n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['target'] = master.apply(get_target, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Active or other    73916\n",
       "Prepaid            2232 \n",
       "Charged-off        35   \n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master['target'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_regions(state):\n",
    "    \n",
    "    \"\"\"\n",
    "    Get region\n",
    "    \"\"\"\n",
    "    \n",
    "    if state in west:\n",
    "        return 'West'\n",
    "    elif state in south_west:\n",
    "        return 'SouthWest'\n",
    "    elif state in south_east:\n",
    "        return 'SouthEast'\n",
    "    elif state in mid_west:\n",
    "        return 'MidWest'\n",
    "    elif state in north_east:\n",
    "        return 'NorthEast'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['region'] = np.nan\n",
    "    \n",
    "master['region'] = master['obligorGeographicLocationLocCurrent'].apply(finding_regions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_year(init):\n",
    "    \n",
    "    \"\"\"\n",
    "    Get origination year\n",
    "    \"\"\"\n",
    "    \n",
    "    year = init[0:4]\n",
    "    \n",
    "    return year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_col = 'originationDateRLocCurrent'\n",
    "\n",
    "year_vals = master[year_col].values\n",
    "years = [get_or_year(y) for y in year_vals]\n",
    "master['originationYear'] = years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['originationDate'] = pd.to_datetime(master['originationDateRLocCurrent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76183, 713)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#master[master['exceptionStatus'].isin([True])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding outcome for transaction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_col = 'id'\n",
    "m_type = 'left'\n",
    "merged = pd.merge(data, master[[m_col, 'target']], on = m_col, how = m_type)\n",
    "ft_shape = merged.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302642"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bool = init_shape == sec_shape == ft_shape\n",
    "log['lengths_match'] = final_bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vals cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_cols = [col for col in list(master.columns) if 'vals' in col.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_vals(row, column):\n",
    "\n",
    "    \"\"\"\n",
    "    Fix column values\n",
    "    \"\"\"\n",
    "\n",
    "    init = str(row[column])\n",
    "\n",
    "    ret_val = 'str: ' + init\n",
    "\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obligorIncomeVerificationLevelCodeValsCurrent\n",
      "interestCalculationTypeCodeValsCurrent\n",
      "zeroBalanceCodeValsCurrent\n",
      "subventedValsCurrent\n",
      "modificationTypeCodeValsCurrent\n",
      "assetSubjectDemandStatusCodeValsCurrent\n",
      "repurchaseReplacementReasonCodeValsCurrent\n",
      "vehicleValueSourceCodeValsCurrent\n",
      "accountStatusValsCurrent\n",
      "obligorEmploymentVerificationCodeValsCurrent\n",
      "originalInterestRateTypeCodeValsCurrent\n",
      "vehicleNewUsedCodeValsCurrent\n",
      "vehicleTypeCodeValsCurrent\n",
      "paymentTypeCodeValsCurrent\n",
      "indexAccountValsCurrent\n",
      "servicingAdvanceMethodCodeValsCurrent\n",
      "indexTransactionValsCurrent\n",
      "zeroBalanceCodeMValsCurrent\n",
      "obligorIncomeVerificationLevelCodeValsPrior\n",
      "interestCalculationTypeCodeValsPrior\n",
      "zeroBalanceCodeValsPrior\n",
      "subventedValsPrior\n",
      "modificationTypeCodeValsPrior\n",
      "assetSubjectDemandStatusCodeValsPrior\n",
      "repurchaseReplacementReasonCodeValsPrior\n",
      "vehicleValueSourceCodeValsPrior\n",
      "accountStatusValsPrior\n",
      "obligorEmploymentVerificationCodeValsPrior\n",
      "originalInterestRateTypeCodeValsPrior\n",
      "vehicleNewUsedCodeValsPrior\n",
      "vehicleTypeCodeValsPrior\n",
      "paymentTypeCodeValsPrior\n",
      "indexAccountValsPrior\n",
      "servicingAdvanceMethodCodeValsPrior\n",
      "indexTransactionValsPrior\n",
      "zeroBalanceCodeMValsPrior\n",
      "obligorIncomeVerificationLevelCodeValsRandom\n",
      "interestCalculationTypeCodeValsRandom\n",
      "zeroBalanceCodeValsRandom\n",
      "subventedValsRandom\n",
      "modificationTypeCodeValsRandom\n",
      "assetSubjectDemandStatusCodeValsRandom\n",
      "repurchaseReplacementReasonCodeValsRandom\n",
      "vehicleValueSourceCodeValsRandom\n",
      "accountStatusValsRandom\n",
      "obligorEmploymentVerificationCodeValsRandom\n",
      "originalInterestRateTypeCodeValsRandom\n",
      "vehicleNewUsedCodeValsRandom\n",
      "vehicleTypeCodeValsRandom\n",
      "paymentTypeCodeValsRandom\n",
      "indexAccountValsRandom\n",
      "servicingAdvanceMethodCodeValsRandom\n",
      "indexTransactionValsRandom\n",
      "zeroBalanceCodeMValsRandom\n"
     ]
    }
   ],
   "source": [
    "for col in vals_cols:\n",
    "    print(col)\n",
    "    master[col] = master[col].astype(str)\n",
    "    master[col] = 'str: ' + master[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/karus_datasets/Santander/Santander 2020-4/'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_folder = 'data/karus_datasets/{}/{} {}/'.format(originator, originator, add_id)\n",
    "export_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_bool = os.path.isdir(export_folder)\n",
    "path_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir exists\n"
     ]
    }
   ],
   "source": [
    "if path_bool == False:\n",
    "    os.mkir(export_folder)\n",
    "    print('dir folder')\n",
    "else:\n",
    "    print('dir exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/karus_datasets/Santander/Santander 2020-4/static.csv\n",
      "(76183, 713)\n"
     ]
    }
   ],
   "source": [
    "#e_folder = 'data/static/'\n",
    "e_file = 'static.csv'.format(add_id)\n",
    "e_path = export_folder + e_file\n",
    "print(e_path)\n",
    "print(master.shape)\n",
    "master.to_csv(e_path, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/karus_datasets/Santander/Santander 2020-4/transaction.csv\n",
      "(302642, 99)\n"
     ]
    }
   ],
   "source": [
    "#t_folder = 'data/transaction/prepared/'\n",
    "t_file = 'transaction.csv'.format(add_id)\n",
    "t_path = export_folder + t_file\n",
    "print(t_path)\n",
    "print(merged.shape)\n",
    "merged.to_csv(t_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export log\n",
    "#j_folder = 'data/static/log/'\n",
    "j_file = '{} log.json'.format(term)\n",
    "j_path = export_folder + j_file\n",
    "with open(j_path, 'w') as outfile:  \n",
    "    json.dump(log, outfile, indent = 4, separators = (',', ': '), sort_keys = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue...\n"
     ]
    }
   ],
   "source": [
    "print('continue...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
