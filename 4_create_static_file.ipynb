{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 12 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from pandarallel import pandarallel\n",
    "import re\n",
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "\n",
    "pandarallel.initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/kn/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "n = 750\n",
    "pd.set_option('display.max_columns', n)\n",
    "pd.set_option('display.max_rows', n)\n",
    "pd.set_option('display.max_colwidth', -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term = 'Santander Drive Auto Receivables Trust 2020-4 Data Tape'\n",
    "finder = re.compile('\\d{4,}\\W\\d{1,}')\n",
    "add_id = re.findall(finder, term)[0]\n",
    "add_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366189, 73)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load abs\n",
    "folder = 'data/transaction/'\n",
    "file = '{}.csv'.format(term)\n",
    "path = folder + file\n",
    "data = pd.read_csv(path)\n",
    "init_shape = data.shape[0]\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fields\n",
    "f_folder = 'data/json/fields/'\n",
    "f_file = 'fields.json'\n",
    "f_path = f_folder + f_file\n",
    "with open(f_path) as f:\n",
    "    fields = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mapper\n",
    "m_folder = 'data/dictionary/mapper/'\n",
    "m_file = 'mapper.json'\n",
    "m_path = m_folder + m_file\n",
    "with open(m_path) as f:\n",
    "    mapper = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_id = fields['init_id'][0]\n",
    "date_cols = fields['dates']\n",
    "replacer_cols = fields['replace_dash']\n",
    "clean_cols = fields['clean']\n",
    "m_cols = fields['map']\n",
    "event_cols = fields['event']\n",
    "loc_cols = fields['all_loc']\n",
    "numeric_cols = fields['numeric']\n",
    "all_vals_cols = fields['all_vals']\n",
    "min_max_cols = fields['min_max']\n",
    "west = fields['regions']['west']\n",
    "south_west = fields['regions']['south_west']\n",
    "south_east = fields['regions']['south_east']\n",
    "mid_west = fields['regions']['mid_west']\n",
    "north_east = fields['regions']['north_east']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID and dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_date(init):\n",
    "    \n",
    "    \"\"\"\n",
    "    Reorder date\n",
    "    \"\"\"\n",
    "    \n",
    "    init = str(init)\n",
    "    if init != '-':\n",
    "        if '/' not in init:\n",
    "            y = init[6:10]\n",
    "            m = init[0:2]\n",
    "            d = init[3:5]\n",
    "            date = y + '-' + m + '-' + d\n",
    "        elif '/' in init:\n",
    "            y = init[3:7]\n",
    "            m = init[0:2]\n",
    "            date = y + '-' + m\n",
    "    else:\n",
    "        date = ''\n",
    "    \n",
    "    return date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['id'] = data[init_id].str.replace('=', '').str.replace('\"', '').str.strip() + '-' + add_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reportingPeriodBeginningDate\n",
      "DemandResolutionDate\n",
      "reportingPeriodEndingDate\n",
      "loanMaturityDate\n",
      "originationDate\n",
      "interestPaidThroughDate\n",
      "originalFirstPaymentDate\n",
      "mostRecentServicingTransferReceivedDate\n",
      "zeroBalanceEffectiveDate\n"
     ]
    }
   ],
   "source": [
    "for col in date_cols:\n",
    "    print(col)\n",
    "    values = data[col].values\n",
    "    dates = [reorder_date(v) for v in values]\n",
    "    data['{}R'.format(col)] = dates\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(302642, 83)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sort_values(by=['reportingPeriodBeginningDateR'], ascending=False)\n",
    "data = data.drop_duplicates(subset = ['id', 'reportingPeriodBeginningDateR'], keep = 'first')\n",
    "sec_shape = data.shape[0]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows\n"
     ]
    }
   ],
   "source": [
    "if init_shape == sec_shape:\n",
    "    dup_rows = False\n",
    "    print('Matching shapes')\n",
    "else:\n",
    "    dup_rows = True \n",
    "    print('Duplicate rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_col = 'loanMaturityDate'\n",
    "# t_col = '{}R'.format(s_col)\n",
    "# data[[s_col, t_col]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[replacer_cols] = data[replacer_cols].replace('-', np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean cols\n",
    "for col in clean_cols:\n",
    "    data[col] = data[col].astype(str)\n",
    "    data[col] = data[col].str.strip()\n",
    "    data[col] = data[col].astype(float)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_val(init, column):\n",
    "    \n",
    "    \"\"\"\n",
    "    Replace numeric values\n",
    "    \"\"\"\n",
    "    \n",
    "    init = str(init).strip().replace(';', '')\n",
    "    if init in ['0', '1', '2', '3', '4', '5', '98', '99']:\n",
    "        mapped = mapper[column][init]\n",
    "        return mapped\n",
    "    else:\n",
    "        if init[0] in ['0', '1', '2', '3', '4', '5']:\n",
    "            use = init[0]\n",
    "        elif init == '-':\n",
    "            use_keys = list(mapper[column].keys())\n",
    "            if '98' in use_keys:\n",
    "                use = '98'\n",
    "            elif '99' in use_keys:\n",
    "                use = '99'\n",
    "        else:\n",
    "            use = init\n",
    "        mapped = mapper[column][use]\n",
    "        \n",
    "    return mapped\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obligorIncomeVerificationLevelCode\n",
      "interestCalculationTypeCode\n",
      "zeroBalanceCode\n",
      "modificationTypeCode\n",
      "assetSubjectDemandStatusCode\n",
      "repurchaseReplacementReasonCode\n",
      "vehicleValueSourceCode\n",
      "obligorEmploymentVerificationCode\n",
      "vehicleNewUsedCode\n",
      "vehicleTypeCode\n",
      "paymentTypeCode\n",
      "servicingAdvanceMethodCode\n",
      "originalInterestRateTypeCode\n",
      "subvented\n"
     ]
    }
   ],
   "source": [
    "for col in m_cols:\n",
    "    print(col)\n",
    "    values = data[col].values\n",
    "    ret_vals = [replace_val(v, col) for v in values]\n",
    "    data['{}M'.format(col)] = ret_vals\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_col = 'subvented'\n",
    "# t_col = '{}M'.format(s_col)\n",
    "# data[[s_col, t_col]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Account status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acct_status(row, b_col, e_col, zero_col, thresh):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create karus account status\n",
    "    \"\"\"\n",
    "    \n",
    "    b = float(row[b_col])\n",
    "    e = float(row[e_col])\n",
    "    z = str(row[zero_col])\n",
    "    \n",
    "    if z in ['Charged-off', 'Repurchased or Replaced']:\n",
    "        res = z\n",
    "        return res\n",
    "    if b < thresh and e < thresh:\n",
    "        res = 'Prepaid or Matured'\n",
    "        return res\n",
    "    if z in ['Unavailable', 'Prepaid or Matured']:\n",
    "        res = z\n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_col = 'reportingPeriodBeginningLoanBalanceAmount'\n",
    "e_col = 'nextReportingPeriodPaymentAmountDue'\n",
    "z_col = 'zeroBalanceCodeM'\n",
    "thresh = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['accountStatus'] = data.parallel_apply(acct_status, args = (b_col, e_col, z_col, thresh, ), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unavailable                300268\n",
       "Prepaid or Matured         2249  \n",
       "Repurchased or Replaced    88    \n",
       "Charged-off                37    \n",
       "Name: accountStatus, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['accountStatus'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currentDelinquencyStatus\n",
      "paymentToIncomePercentage\n",
      "paymentExtendedNumber\n",
      "otherAssessedUncollectedServicerFeeAmount\n",
      "totalActualAmountPaid\n",
      "actualInterestCollectedAmount\n",
      "remainingTermToMaturityNumber\n",
      "reportingPeriodScheduledPaymentAmount\n",
      "vehicleValueAmount\n",
      "reportingPeriodInterestRatePercentage\n",
      "scheduledInterestAmount\n",
      "actualPrincipalCollectedAmount\n",
      "actualOtherCollectedAmount\n",
      "reportingPeriodActualEndBalanceAmount\n",
      "servicingFlatFeeAmount\n",
      "chargedoffPrincipalAmount\n",
      "servicingFeePercentage\n",
      "otherPrincipalAdjustmentAmount\n",
      "obligorCreditScore\n",
      "originalInterestRatePercentage\n",
      "nextReportingPeriodPaymentAmountDue\n",
      "gracePeriodNumber\n",
      "originalLoanTerm\n",
      "repurchaseAmount\n",
      "recoveredAmount\n",
      "servicerAdvancedAmount\n",
      "originalLoanAmount\n",
      "repossessedProceedsAmount\n",
      "nextInterestRatePercentage\n",
      "scheduledPrincipalAmount\n",
      "reportingPeriodBeginningLoanBalanceAmount\n"
     ]
    }
   ],
   "source": [
    "# force convert cols to numeric\n",
    "for col in numeric_cols:\n",
    "    print(col)\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = 'id'\n",
    "status_col = 'accountStatus'\n",
    "values = ['Charged-off', 'Prepaid or Matured', 'Repurchased or Replaced']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76183"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = list(data[id_col].unique())\n",
    "#all_ids = all_ids[:1000]\n",
    "print_vals = list(range(0, len(all_ids), 100))\n",
    "len(all_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break ids into list chunks\n",
    "num = 1000\n",
    "id_lists = [all_ids[i:i + num] for i in range(0, len(all_ids), num)]  \n",
    "#id_lists = [id_lists[-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_static(df, exception_status):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create static df\n",
    "    \"\"\"\n",
    "    \n",
    "    #df = init.reset_values(drop = True)\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    df = df.sort_values('reportingPeriodBeginningDateR', ascending = False)\n",
    "    df['indexAccount'] = df.index\n",
    "    _id = df[id_col].iloc[0]\n",
    "\n",
    "    # dict\n",
    "    account_dict = {}\n",
    "    account_dict['exceptionStatus'] = exception_status\n",
    "    account_dict[id_col] = _id\n",
    "    account_dict['records'] = len(df)\n",
    "\n",
    "    # current status of loan\n",
    "    for col in loc_cols:\n",
    "        account_dict['{}LocCurrent'.format(col)] = df[col].iloc[0]\n",
    "    for col in min_max_cols:\n",
    "        account_dict['{}MaxCurrent'.format(col)] = df[col].max()\n",
    "        account_dict['{}MinCurrent'.format(col)] = df[col].min()\n",
    "    for col in all_vals_cols:\n",
    "        vals = list(df[col].unique())\n",
    "        use_vals = ' | '.join(str(val) for val in vals)\n",
    "        account_dict['{}ValsCurrent'.format(col)] = use_vals\n",
    "    for col in numeric_cols:\n",
    "        _sum = df[col].sum()\n",
    "        account_dict['{}SumCurrent'.format(col)] = _sum\n",
    "        vec = list(df[col])\n",
    "        vec = [v for v in vec if str(v) != 'nan']\n",
    "        if len(vec) > 0:\n",
    "            _len = len(vec)\n",
    "            weights = sorted([1 + i for i in list(range(_len))], reverse=True)\n",
    "            wa = np.average(vec, weights=weights)\n",
    "            account_dict['{}WeightedCurrent'.format(col)] = wa\n",
    "        else:\n",
    "            account_dict['{}WeightedCurrent'.format(col)] = 0\n",
    "\n",
    "    # event information\n",
    "    init_vals = list(df[status_col].unique())\n",
    "    inter = list(set(values).intersection(init_vals))\n",
    "    if len(inter) > 0:\n",
    "        account_dict['eventOccurred'] = 1\n",
    "        n = df[status_col].where(df[status_col].isin(values)).last_valid_index()\n",
    "        account_dict['eventIndex'] = n\n",
    "        n_bool = True\n",
    "        single = df.loc[[n]]\n",
    "        for col in event_cols:\n",
    "            account_dict['{}Event'.format(col)] = single[col].iloc[0]\n",
    "\n",
    "        # prior to event\n",
    "        init = n+1\n",
    "        sub = df[init:len(df)]\n",
    "        sub.reset_index(drop = True, inplace = True)\n",
    "        account_dict['priorHistory'] = len(sub)\n",
    "        sub_bool = True\n",
    "        if len(sub) > 0:\n",
    "            for col in loc_cols:\n",
    "                account_dict['{}LocPrior'.format(col)] = sub[col].iloc[0]\n",
    "            for col in min_max_cols:\n",
    "                account_dict['{}MinPrior'.format(col)] = sub[col].min()\n",
    "                account_dict['{}MaxPrior'.format(col)] = sub[col].max()\n",
    "            for col in all_vals_cols:\n",
    "                vals = list(sub[col].unique())\n",
    "                use_vals = ' | '.join(str(val) for val in vals)\n",
    "                account_dict['{}ValsPrior'.format(col)] = use_vals\n",
    "            for col in numeric_cols:\n",
    "                account_dict['{}SumPrior'.format(col)] = sub[col].sum()\n",
    "                vec = list(sub[col])\n",
    "                vec = [v for v in vec if str(v) != 'nan']\n",
    "                if len(vec) > 0:\n",
    "                    _len = len(vec)\n",
    "                    weights = sorted([1 + i for i in list(range(_len))], reverse=True)\n",
    "                    wa = np.average(vec, weights=weights)\n",
    "                    account_dict['{}WeightedPrior'.format(col)] = wa\n",
    "                else:\n",
    "                    account_dict['{}WeightedPrior'.format(col)] = 0\n",
    "\n",
    "            # random\n",
    "            len_sub = len(sub)            \n",
    "            s = random.randint(0, len_sub)\n",
    "            if s == len_sub:\n",
    "                s = s -1\n",
    "            r_sub = sub[s:len_sub].reset_index(drop = True)\n",
    "            account_dict['randomIndex'] = s\n",
    "            for col in loc_cols:\n",
    "                account_dict['{}LocRandom'.format(col)] = r_sub[col].iloc[0]\n",
    "            for col in min_max_cols:\n",
    "                account_dict['{}MinRandom'.format(col)] = r_sub[col].min()\n",
    "                account_dict['{}MaxRandom'.format(col)] = r_sub[col].max()\n",
    "            for col in all_vals_cols:\n",
    "                vals = list(r_sub[col].unique())\n",
    "                use_vals = ' | '.join(str(val) for val in vals)\n",
    "                account_dict['{}ValsRandom'.format(col)] = use_vals\n",
    "            for col in numeric_cols:\n",
    "                account_dict['{}SumRandom'.format(col)] = r_sub[col].sum()\n",
    "                vec = list(r_sub[col])\n",
    "                vec = [v for v in vec if str(v) != 'nan']\n",
    "                if len(vec) > 0:\n",
    "                    _len = len(vec)\n",
    "                    weights = sorted([1 + i for i in list(range(_len))], reverse=True)\n",
    "                    wa = np.average(vec, weights=weights)\n",
    "                    account_dict['{}WeightedRandom'.format(col)] = wa\n",
    "                else:\n",
    "                    account_dict['{}WeightedRandom'.format(col)] = 0\n",
    "\n",
    "        # if event is first row of sub       \n",
    "        else:\n",
    "            for col in loc_cols:\n",
    "                account_dict['{}LocPrior'.format(col)] = df[col].iloc[0]\n",
    "            for col in min_max_cols:\n",
    "                account_dict['{}MinPrior'.format(col)] = df[col].min()\n",
    "                account_dict['{}MaxPrior'.format(col)] = df[col].max()\n",
    "            for col in all_vals_cols:\n",
    "                vals = list(df[col].unique())\n",
    "                use_vals = ' | '.join(str(val) for val in vals)\n",
    "                account_dict['{}ValsPrior'.format(col)] = use_vals\n",
    "            for col in numeric_cols:\n",
    "                account_dict['{}SumPrior'.format(col)] = df[col].sum()\n",
    "                account_dict['{}WeightedPrior'.format(col)] = df[col].iloc[0]\n",
    "\n",
    "    # if no event        \n",
    "    else:\n",
    "        account_dict['eventOccurred'] = 0\n",
    "        account_dict['priorHistory'] = len(df)\n",
    "        sub_bool = False\n",
    "        n_bool = False\n",
    "        for col in event_cols:\n",
    "            account_dict['{}Event'.format(col)] = np.nan\n",
    "        for col in loc_cols:\n",
    "            account_dict['{}LocPrior'.format(col)] = np.nan\n",
    "        for col in min_max_cols:\n",
    "            account_dict['{}MinPrior'.format(col)] = np.nan\n",
    "            account_dict['{}MaxPrior'.format(col)] = np.nan\n",
    "        for col in all_vals_cols:\n",
    "            account_dict['{}ValsPrior'.format(col)] = np.nan\n",
    "        for col in numeric_cols:\n",
    "            account_dict['{}SumPrior'.format(col)] = np.nan\n",
    "            account_dict['{}WeightedPrior'.format(col)] = np.nan\n",
    "\n",
    "        # random set to nan\n",
    "        account_dict['randomIndex'] = np.nan\n",
    "        for col in loc_cols:\n",
    "            account_dict['{}LocRandom'.format(col)] = np.nan\n",
    "        for col in min_max_cols:\n",
    "            account_dict['{}MinRandom'.format(col)] = np.nan\n",
    "            account_dict['{}MaxRandom'.format(col)] = np.nan\n",
    "        for col in all_vals_cols:\n",
    "            account_dict['{}ValsRandom'.format(col)] = np.nan\n",
    "        for col in numeric_cols:\n",
    "            account_dict['{}SumRandom'.format(col)] = np.nan\n",
    "            account_dict['{}WeightedRandom'.format(col)] = np.nan\n",
    "\n",
    "    return account_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.01312628801701167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/kn/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HITTING EXCEPTION\n",
      "15.818984985351562\n",
      "16.678770780563354\n",
      "-----------------------------\n",
      "2000 0.02625257603402334\n",
      "HITTING EXCEPTION\n",
      "16.023860931396484\n",
      "33.25091910362244\n",
      "-----------------------------\n",
      "3000 0.03937886405103501\n",
      "HITTING EXCEPTION\n",
      "15.082980155944824\n",
      "48.908987045288086\n",
      "-----------------------------\n",
      "4000 0.05250515206804668\n",
      "HITTING EXCEPTION\n",
      "15.36239504814148\n",
      "64.7528748512268\n",
      "-----------------------------\n",
      "5000 0.06563144008505835\n",
      "HITTING EXCEPTION\n",
      "16.711899995803833\n",
      "82.0361099243164\n",
      "-----------------------------\n",
      "6000 0.07875772810207002\n",
      "HITTING EXCEPTION\n",
      "17.747890949249268\n",
      "100.35337281227112\n",
      "-----------------------------\n",
      "7000 0.09188401611908169\n",
      "HITTING EXCEPTION\n",
      "17.532722234725952\n",
      "118.43884205818176\n",
      "-----------------------------\n",
      "8000 0.10501030413609336\n",
      "HITTING EXCEPTION\n",
      "18.03433918952942\n",
      "137.11513805389404\n",
      "-----------------------------\n",
      "9000 0.11813659215310503\n",
      "HITTING EXCEPTION\n",
      "14.332783222198486\n",
      "152.05483984947205\n",
      "-----------------------------\n",
      "10000 0.1312628801701167\n",
      "HITTING EXCEPTION\n",
      "14.861829042434692\n",
      "167.38780999183655\n",
      "-----------------------------\n",
      "11000 0.14438916818712835\n",
      "HITTING EXCEPTION\n",
      "13.993921995162964\n",
      "181.81187295913696\n",
      "-----------------------------\n",
      "12000 0.15751545620414004\n",
      "HITTING EXCEPTION\n",
      "14.525421857833862\n",
      "196.88739800453186\n",
      "-----------------------------\n",
      "13000 0.1706417442211517\n",
      "HITTING EXCEPTION\n",
      "14.661956787109375\n",
      "212.01941013336182\n",
      "-----------------------------\n",
      "14000 0.18376803223816338\n",
      "HITTING EXCEPTION\n",
      "13.43611192703247\n",
      "225.89379286766052\n",
      "-----------------------------\n",
      "15000 0.19689432025517503\n",
      "HITTING EXCEPTION\n",
      "13.94930624961853\n",
      "240.35148882865906\n",
      "-----------------------------\n",
      "16000 0.21002060827218672\n",
      "HITTING EXCEPTION\n",
      "13.70617389678955\n",
      "254.52057790756226\n",
      "-----------------------------\n",
      "17000 0.22314689628919837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/kn/lib/python3.7/site-packages/ipykernel_launcher.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.773522853851318\n",
      "269.79128789901733\n",
      "-----------------------------\n",
      "18000 0.23627318430621005\n",
      "HITTING EXCEPTION\n",
      "14.483197927474976\n",
      "284.8227639198303\n",
      "-----------------------------\n",
      "19000 0.2493994723232217\n",
      "14.104943990707397\n",
      "299.39719700813293\n",
      "-----------------------------\n",
      "20000 0.2625257603402334\n",
      "HITTING EXCEPTION\n",
      "14.910669088363647\n",
      "314.77772998809814\n",
      "-----------------------------\n",
      "21000 0.27565204835724505\n",
      "HITTING EXCEPTION\n",
      "15.32523488998413\n",
      "330.6056020259857\n",
      "-----------------------------\n",
      "22000 0.2887783363742567\n",
      "14.89021897315979\n",
      "345.9832260608673\n",
      "-----------------------------\n",
      "23000 0.3019046243912684\n",
      "HITTING EXCEPTION\n",
      "13.282132148742676\n",
      "359.69128012657166\n",
      "-----------------------------\n",
      "24000 0.3150309124082801\n",
      "HITTING EXCEPTION\n",
      "13.919404029846191\n",
      "374.0814571380615\n",
      "-----------------------------\n",
      "25000 0.32815720042529173\n",
      "HITTING EXCEPTION\n",
      "13.58312201499939\n",
      "388.20246291160583\n",
      "-----------------------------\n",
      "26000 0.3412834884423034\n",
      "HITTING EXCEPTION\n",
      "13.889235973358154\n",
      "402.57178378105164\n",
      "-----------------------------\n",
      "27000 0.3544097764593151\n",
      "HITTING EXCEPTION\n",
      "13.483466148376465\n",
      "416.5614368915558\n",
      "-----------------------------\n",
      "28000 0.36753606447632675\n",
      "HITTING EXCEPTION\n",
      "13.982468128204346\n",
      "431.02617597579956\n",
      "-----------------------------\n",
      "29000 0.3806623524933384\n",
      "HITTING EXCEPTION\n",
      "13.950592041015625\n",
      "445.4466700553894\n",
      "-----------------------------\n",
      "30000 0.39378864051035006\n",
      "HITTING EXCEPTION\n",
      "13.452047109603882\n",
      "459.43338894844055\n",
      "-----------------------------\n",
      "31000 0.4069149285273618\n",
      "HITTING EXCEPTION\n",
      "14.193387985229492\n",
      "474.147910118103\n",
      "-----------------------------\n",
      "32000 0.42004121654437343\n",
      "HITTING EXCEPTION\n",
      "13.781943082809448\n",
      "488.4589648246765\n",
      "-----------------------------\n",
      "33000 0.4331675045613851\n",
      "HITTING EXCEPTION\n",
      "13.62051510810852\n",
      "502.5357599258423\n",
      "-----------------------------\n",
      "34000 0.44629379257839674\n",
      "HITTING EXCEPTION\n",
      "13.568901300430298\n",
      "516.5757238864899\n",
      "-----------------------------\n",
      "35000 0.4594200805954084\n",
      "HITTING EXCEPTION\n",
      "12.931179761886597\n",
      "530.0251278877258\n",
      "-----------------------------\n",
      "36000 0.4725463686124201\n",
      "HITTING EXCEPTION\n",
      "13.268046140670776\n",
      "543.7288949489594\n",
      "-----------------------------\n",
      "37000 0.48567265662943176\n",
      "HITTING EXCEPTION\n",
      "12.94850206375122\n",
      "557.1197481155396\n",
      "-----------------------------\n",
      "38000 0.4987989446464434\n",
      "HITTING EXCEPTION\n",
      "13.723242044448853\n",
      "571.353541135788\n",
      "-----------------------------\n",
      "39000 0.5119252326634551\n",
      "HITTING EXCEPTION\n",
      "12.723804950714111\n",
      "584.5173768997192\n",
      "-----------------------------\n",
      "40000 0.5250515206804668\n",
      "HITTING EXCEPTION\n",
      "13.149497032165527\n",
      "598.1319320201874\n",
      "-----------------------------\n",
      "41000 0.5381778086974784\n",
      "HITTING EXCEPTION\n",
      "13.099627017974854\n",
      "611.745677947998\n",
      "-----------------------------\n",
      "42000 0.5513040967144901\n",
      "HITTING EXCEPTION\n",
      "13.675747871398926\n",
      "625.880040884018\n",
      "-----------------------------\n",
      "43000 0.5644303847315018\n",
      "HITTING EXCEPTION\n",
      "14.062365055084229\n",
      "640.4255127906799\n",
      "-----------------------------\n",
      "44000 0.5775566727485134\n",
      "HITTING EXCEPTION\n",
      "14.089011907577515\n",
      "655.1290788650513\n",
      "-----------------------------\n",
      "45000 0.5906829607655251\n",
      "HITTING EXCEPTION\n",
      "15.362356185913086\n",
      "671.0066831111908\n",
      "-----------------------------\n",
      "46000 0.6038092487825368\n",
      "HITTING EXCEPTION\n",
      "14.7517569065094\n",
      "686.2618138790131\n",
      "-----------------------------\n",
      "47000 0.6169355367995485\n",
      "HITTING EXCEPTION\n",
      "14.924487352371216\n",
      "701.7172429561615\n",
      "-----------------------------\n",
      "48000 0.6300618248165601\n",
      "HITTING EXCEPTION\n",
      "15.706531286239624\n",
      "717.9148478507996\n",
      "-----------------------------\n",
      "49000 0.6431881128335718\n",
      "HITTING EXCEPTION\n",
      "14.148104190826416\n",
      "732.5971579551697\n",
      "-----------------------------\n",
      "50000 0.6563144008505835\n",
      "HITTING EXCEPTION\n",
      "14.058474063873291\n",
      "747.1363770961761\n",
      "-----------------------------\n",
      "51000 0.6694406888675951\n",
      "14.278162956237793\n",
      "761.7851178646088\n",
      "-----------------------------\n",
      "52000 0.6825669768846068\n",
      "HITTING EXCEPTION\n",
      "13.902135848999023\n",
      "776.1255657672882\n",
      "-----------------------------\n",
      "53000 0.6956932649016184\n",
      "HITTING EXCEPTION\n",
      "13.547399044036865\n",
      "790.1366560459137\n",
      "-----------------------------\n",
      "54000 0.7088195529186302\n",
      "HITTING EXCEPTION\n",
      "13.560186862945557\n",
      "804.1633367538452\n",
      "-----------------------------\n",
      "55000 0.7219458409356418\n",
      "HITTING EXCEPTION\n",
      "14.064201831817627\n",
      "818.7587208747864\n",
      "-----------------------------\n",
      "56000 0.7350721289526535\n",
      "13.543672800064087\n",
      "832.7429859638214\n",
      "-----------------------------\n",
      "57000 0.7481984169696652\n",
      "HITTING EXCEPTION\n",
      "14.224782228469849\n",
      "847.4510979652405\n",
      "-----------------------------\n",
      "58000 0.7613247049866768\n",
      "13.954412698745728\n",
      "861.911111831665\n",
      "-----------------------------\n",
      "59000 0.7744509930036885\n",
      "13.347100973129272\n",
      "875.6231439113617\n",
      "-----------------------------\n",
      "60000 0.7875772810207001\n",
      "HITTING EXCEPTION\n",
      "12.580025911331177\n",
      "888.6712648868561\n",
      "-----------------------------\n",
      "61000 0.8007035690377118\n",
      "HITTING EXCEPTION\n",
      "14.755486011505127\n",
      "903.980456829071\n",
      "-----------------------------\n",
      "62000 0.8138298570547235\n",
      "HITTING EXCEPTION\n",
      "14.780930042266846\n",
      "919.2494010925293\n",
      "-----------------------------\n",
      "63000 0.8269561450717352\n",
      "HITTING EXCEPTION\n",
      "14.941107988357544\n",
      "934.753849029541\n",
      "-----------------------------\n",
      "64000 0.8400824330887469\n",
      "HITTING EXCEPTION\n",
      "15.647398233413696\n",
      "950.9105451107025\n",
      "-----------------------------\n",
      "65000 0.8532087211057585\n",
      "HITTING EXCEPTION\n",
      "16.102770805358887\n",
      "967.5493049621582\n",
      "-----------------------------\n",
      "66000 0.8663350091227702\n",
      "HITTING EXCEPTION\n",
      "16.249741792678833\n",
      "984.3932149410248\n",
      "-----------------------------\n",
      "67000 0.8794612971397818\n",
      "HITTING EXCEPTION\n",
      "16.571518898010254\n",
      "1001.5023519992828\n",
      "-----------------------------\n",
      "68000 0.8925875851567935\n",
      "HITTING EXCEPTION\n",
      "14.852863073348999\n",
      "1016.9076099395752\n",
      "-----------------------------\n",
      "69000 0.9057138731738051\n",
      "13.284358263015747\n",
      "1030.6611459255219\n",
      "-----------------------------\n",
      "70000 0.9188401611908168\n",
      "HITTING EXCEPTION\n",
      "12.899197101593018\n",
      "1044.0489339828491\n",
      "-----------------------------\n",
      "71000 0.9319664492078286\n",
      "HITTING EXCEPTION\n",
      "12.897645950317383\n",
      "1057.389545917511\n",
      "-----------------------------\n",
      "72000 0.9450927372248402\n",
      "HITTING EXCEPTION\n",
      "13.446581840515137\n",
      "1071.3347837924957\n",
      "-----------------------------\n",
      "73000 0.9582190252418519\n",
      "HITTING EXCEPTION\n",
      "13.527997970581055\n",
      "1085.283066034317\n",
      "-----------------------------\n",
      "74000 0.9713453132588635\n",
      "HITTING EXCEPTION\n",
      "12.841017246246338\n",
      "1098.564160823822\n",
      "-----------------------------\n",
      "75000 0.9844716012758752\n",
      "18.072981119155884\n",
      "1117.0412657260895\n",
      "-----------------------------\n",
      "76000 0.9975978892928868\n",
      "37.631263971328735\n",
      "1155.0508949756622\n",
      "-----------------------------\n",
      "76183 1.0\n",
      "HITTING EXCEPTION\n",
      "6.963111877441406\n",
      "1162.140882730484\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "log = {}\n",
    "log['securitization'] = term\n",
    "master_list = []\n",
    "broke = 0\n",
    "cautions = 0\n",
    "status = 'good'\n",
    "s1 = time.time()\n",
    "ids_count = 0\n",
    "for ids in id_lists:\n",
    "    \n",
    "    # get update\n",
    "    ids_count = ids_count + len(ids)\n",
    "    percent = ids_count / len(all_ids)\n",
    "    print(ids_count, percent)\n",
    "    \n",
    "    # create sub\n",
    "    sub_df = data[data[id_col].isin(ids)]\n",
    "    sub_df['indexTransaction'] = sub_df.index\n",
    "    sub_df = sub_df.reset_index(drop = True)\n",
    "    splits = list(sub_df.groupby(id_col)) \n",
    "    l = [splits[n_][1] for n_ in list(range(len(splits)))]\n",
    "    a = np.array(l)\n",
    "    \n",
    "    # get results\n",
    "    s2 = time.time()\n",
    "    try:\n",
    "        exception_status = False\n",
    "        results = [convert_static(d, exception_status) for d in a]\n",
    "        for r in results:\n",
    "            master_list.append(r)\n",
    "    except:\n",
    "        try:\n",
    "            exception_status = True \n",
    "            cautions = cautions + 1\n",
    "            print('HITTING EXCEPTION')\n",
    "            for l2 in l:\n",
    "                res = convert_static(l2, exception_status)\n",
    "                master_list.append(res)\n",
    "        except:\n",
    "            status = 'bad'\n",
    "            broke = broke + 1\n",
    "            if broke > 0:\n",
    "                sys.exit('Too many errors...')\n",
    "    \n",
    "    e1 = time.time()\n",
    "    e2 = time.time()\n",
    "    log['{}'.format(ids_count)] = (e2 - s2)\n",
    "    \n",
    "    print(e2 - s2)\n",
    "    print(e1 - s1)\n",
    "    print('-----------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "log['total_time'] = e1 - s1\n",
    "log['run_status'] = status\n",
    "log['cautions'] = cautions\n",
    "log['duplicate_rows'] = dup_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.DataFrame(master_list)\n",
    "log['loans'] = len(master)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = master['obligorCreditScoreLocCurrent'].mean()\n",
    "if cs <= 600:\n",
    "    rating = 'sub_prime'\n",
    "elif cs > 600 and cs <= 700:\n",
    "    rating = 'near_prime'\n",
    "elif cs > 720:\n",
    "    rating = 'prime'\n",
    "else:\n",
    "    rating = 'other'\n",
    "log['average_credit'] = cs\n",
    "log['rating'] = rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_ids) == len(master_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                        73836\n",
       "Prepaid or Matured         2232 \n",
       "Repurchased or Replaced    80   \n",
       "Charged-off                35   \n",
       "Name: accountStatusEvent, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master['accountStatusEvent'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding final fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['securitization'] = term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(row):\n",
    "    \n",
    "    \"\"\"\n",
    "    Set target var\n",
    "    \"\"\"\n",
    "    \n",
    "    init = str(row['accountStatusEvent'])\n",
    "    remaining = row['remainingTermToMaturityNumberMinPrior']\n",
    "    #remaining = row['remainingTermToMaturityNumberLocCurrent']\n",
    "    #remaining = row['remainingTermToMaturityNumberLocPrior']\n",
    "    \n",
    "    if init == 'Charged-off':\n",
    "        res = 'Charged-off'\n",
    "        return res\n",
    "    elif init == 'Prepaid or Matured' and remaining > 1:\n",
    "        res = 'Prepaid'\n",
    "        return res\n",
    "    elif init == 'Prepaid or Matured' and remaining < 2:\n",
    "        res = 'Closed'\n",
    "        return res\n",
    "    elif init == 'nan':\n",
    "        res = 'Active or other'\n",
    "        return res\n",
    "    else:\n",
    "        res = 'Active or other'\n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['target'] = master.apply(get_target, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Active or other    73916\n",
       "Prepaid            2232 \n",
       "Charged-off        35   \n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master['target'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_regions(state):\n",
    "    \n",
    "    \"\"\"\n",
    "    Get region\n",
    "    \"\"\"\n",
    "    \n",
    "    if state in west:\n",
    "        return 'West'\n",
    "    elif state in south_west:\n",
    "        return 'SouthWest'\n",
    "    elif state in south_east:\n",
    "        return 'SouthEast'\n",
    "    elif state in mid_west:\n",
    "        return 'MidWest'\n",
    "    elif state in north_east:\n",
    "        return 'NorthEast'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['region'] = np.nan\n",
    "    \n",
    "master['region'] = master['obligorGeographicLocationLocCurrent'].apply(finding_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_year(init):\n",
    "    \n",
    "    \"\"\"\n",
    "    Get origination year\n",
    "    \"\"\"\n",
    "    \n",
    "    year = init[0:4]\n",
    "    \n",
    "    return year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_col = 'originationDateRLocCurrent'\n",
    "\n",
    "year_vals = master[year_col].values\n",
    "years = [get_or_year(y) for y in year_vals]\n",
    "master['originationYear'] = years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "master['originationDate'] = pd.to_datetime(master['originationDateRLocCurrent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76183, 713)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#master[master['exceptionStatus'].isin([True])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding outcome for transaction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_col = 'id'\n",
    "m_type = 'left'\n",
    "merged = pd.merge(data, master[[m_col, 'target']], on = m_col, how = m_type)\n",
    "ft_shape = merged.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302642"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bool = init_shape == sec_shape == ft_shape\n",
    "log['lengths_match'] = final_bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vals cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_cols = [col for col in list(master.columns) if 'vals' in col.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_vals(row, column):\n",
    "\n",
    "    \"\"\"\n",
    "    Fix column values\n",
    "    \"\"\"\n",
    "\n",
    "    init = str(row[column])\n",
    "\n",
    "    ret_val = 'str: ' + init\n",
    "\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obligorIncomeVerificationLevelCodeValsCurrent\n",
      "interestCalculationTypeCodeValsCurrent\n",
      "zeroBalanceCodeValsCurrent\n",
      "subventedValsCurrent\n",
      "modificationTypeCodeValsCurrent\n",
      "assetSubjectDemandStatusCodeValsCurrent\n",
      "repurchaseReplacementReasonCodeValsCurrent\n",
      "vehicleValueSourceCodeValsCurrent\n",
      "accountStatusValsCurrent\n",
      "obligorEmploymentVerificationCodeValsCurrent\n",
      "originalInterestRateTypeCodeValsCurrent\n",
      "vehicleNewUsedCodeValsCurrent\n",
      "vehicleTypeCodeValsCurrent\n",
      "paymentTypeCodeValsCurrent\n",
      "indexAccountValsCurrent\n",
      "servicingAdvanceMethodCodeValsCurrent\n",
      "indexTransactionValsCurrent\n",
      "zeroBalanceCodeMValsCurrent\n",
      "obligorIncomeVerificationLevelCodeValsPrior\n",
      "interestCalculationTypeCodeValsPrior\n",
      "zeroBalanceCodeValsPrior\n",
      "subventedValsPrior\n",
      "modificationTypeCodeValsPrior\n",
      "assetSubjectDemandStatusCodeValsPrior\n",
      "repurchaseReplacementReasonCodeValsPrior\n",
      "vehicleValueSourceCodeValsPrior\n",
      "accountStatusValsPrior\n",
      "obligorEmploymentVerificationCodeValsPrior\n",
      "originalInterestRateTypeCodeValsPrior\n",
      "vehicleNewUsedCodeValsPrior\n",
      "vehicleTypeCodeValsPrior\n",
      "paymentTypeCodeValsPrior\n",
      "indexAccountValsPrior\n",
      "servicingAdvanceMethodCodeValsPrior\n",
      "indexTransactionValsPrior\n",
      "zeroBalanceCodeMValsPrior\n",
      "obligorIncomeVerificationLevelCodeValsRandom\n",
      "interestCalculationTypeCodeValsRandom\n",
      "zeroBalanceCodeValsRandom\n",
      "subventedValsRandom\n",
      "modificationTypeCodeValsRandom\n",
      "assetSubjectDemandStatusCodeValsRandom\n",
      "repurchaseReplacementReasonCodeValsRandom\n",
      "vehicleValueSourceCodeValsRandom\n",
      "accountStatusValsRandom\n",
      "obligorEmploymentVerificationCodeValsRandom\n",
      "originalInterestRateTypeCodeValsRandom\n",
      "vehicleNewUsedCodeValsRandom\n",
      "vehicleTypeCodeValsRandom\n",
      "paymentTypeCodeValsRandom\n",
      "indexAccountValsRandom\n",
      "servicingAdvanceMethodCodeValsRandom\n",
      "indexTransactionValsRandom\n",
      "zeroBalanceCodeMValsRandom\n"
     ]
    }
   ],
   "source": [
    "for col in vals_cols:\n",
    "    print(col)\n",
    "    master[col] = master[col].astype(str)\n",
    "    master[col] = 'str: ' + master[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/static/Santander Drive Auto Receivables Trust 2020-4 Data Tape static.csv\n",
      "(76183, 713)\n"
     ]
    }
   ],
   "source": [
    "e_folder = 'data/static/'\n",
    "e_file = '{} static.csv'.format(term)\n",
    "e_path = e_folder + e_file\n",
    "print(e_path)\n",
    "print(master.shape)\n",
    "master.to_csv(e_path, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/transaction/prepared/Santander Drive Auto Receivables Trust 2020-4 Data Tape transaction.csv\n",
      "(302642, 99)\n"
     ]
    }
   ],
   "source": [
    "t_folder = 'data/transaction/prepared/'\n",
    "t_file = '{} transaction.csv'.format(term)\n",
    "t_path = t_folder + t_file\n",
    "print(t_path)\n",
    "print(merged.shape)\n",
    "merged.to_csv(t_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export log\n",
    "j_folder = 'data/static/log/'\n",
    "j_file = '{} log.json'.format(term)\n",
    "j_path = j_folder + j_file\n",
    "with open(j_path, 'w') as outfile:  \n",
    "    json.dump(log, outfile, indent = 4, separators = (',', ': '), sort_keys = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue...\n"
     ]
    }
   ],
   "source": [
    "print('continue...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
